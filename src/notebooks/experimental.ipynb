{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental ground: random collection of approaches and testing of different functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries \n",
    "import numpy as np\n",
    "import time\n",
    "import h5py\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import HBox, VBox\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import binary_erosion\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import display\n",
    "import sys\n",
    "import math\n",
    "sys.path.insert(0, '../../src')\n",
    "\n",
    "# from Network.PatchHandler3D import PatchHandler3D\n",
    "# functions\n",
    "from testing.test_iterator import check_compatibility, load_indexes\n",
    "from Network.PatchHandler3D_temporal import PatchHandler4D\n",
    "import prepare_data.fft_downsampling as fft_fcts\n",
    "# from utils.evaluate_utils import *\n",
    "from prepare_data.h5functions import save_to_h5\n",
    "from utils.evaluate_utils import *\n",
    "plt.rcParams['figure.figsize'] = [5, 5]\n",
    "from utils.colors import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "# create gifs\n",
    "\n",
    "def create_gif(directory_path, gif_path, includes = ''):\n",
    "    # Get all image files in the directory\n",
    "    image_files = [f for f in os.listdir(directory_path) if f.endswith('.png')]\n",
    "    # only include those conatin 'inclusion' word\n",
    "    image_files = [f for f in image_files if includes in f]\n",
    "\n",
    "    # Sort the image files by name\n",
    "    image_files.sort()\n",
    "\n",
    "    # Create a list to store the image frames\n",
    "    frames = []\n",
    "\n",
    "    # Load each image and append it to the frames list\n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(directory_path, image_file)\n",
    "        image = Image.open(image_path)\n",
    "        frames.append(image)\n",
    "\n",
    "    # Save the frames as a GIF\n",
    "    frames[0].save(gif_path, format='GIF', append_images=frames[1:], save_all=True, duration=200, loop=0)\n",
    "\n",
    "# Example usage\n",
    "\n",
    "directory_path = f'/mnt/c/Users/piacal/Code/SuperResolution4DFlowMRI/Temporal4DFlowNet/results/data/insilico/Model_6'\n",
    "# create_gif(directory_path, f'{directory_path}/magn.gif', includes='magn')\n",
    "# create_gif(directory_path, f'{directory_path}/vectorfield.gif', includes='vectorfield')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# prepare some coordinates\n",
    "x, y, z = np.indices((5, 5, 5))\n",
    "\n",
    "# draw cuboids in the top left and bottom right corners, and a link between\n",
    "# them\n",
    "cube1 = (x < 3) & (y < 3) & (z < 3)\n",
    "link = abs(x - y) + abs(y - z) + abs(z - x) <= 2\n",
    "\n",
    "# combine the objects into a single boolean array\n",
    "voxelarray = cube1 | cube2 | link\n",
    "\n",
    "# set the colors of each object\n",
    "colors = np.empty(voxelarray.shape, dtype=object)\n",
    "colors[link] = 'red'\n",
    "colors[cube1] = 'blue'\n",
    "\n",
    "# and plot everything\n",
    "ax = plt.figure().add_subplot(projection='3d', proj_type = 'ortho')\n",
    "ax.voxels(voxelarray, facecolors=colors, edgecolor='k', shade=False)\n",
    "\n",
    "# ax.view_init(elev=17, azim=-80, roll = 2.1)\n",
    "# ax.view_init(elev=20, azim=-80, )\n",
    "ax.view_init(elev=20, azim=95, roll = 1.5)\n",
    "plt.show()\n",
    "\n",
    "# ax.view_init(elev=10, azim=-80, roll = 1)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "path_model = f'/mnt/c/Users/piacal/Code/SuperResolution4DFlowMRI/Temporal4DFlowNet/data/CARDIAC/M1_2mm_step2_static_dynamic.h5'\n",
    "\n",
    "with h5py.File(path_model, 'r') as hf:\n",
    "    u = np.array(hf['u'])[0]\n",
    "    mask = np.array(hf['mask'])[0]\n",
    "\n",
    "\n",
    "venc = np.max(u)\n",
    "cmp_img = np.multiply(mask, (1j*(u/venc*np.pi)))\n",
    "ksp_full = np.abs(fft_fcts.complex_image_to_centered_kspace(cmp_img))\n",
    "\n",
    "#normalisera\n",
    "ksp_full = np.log(ksp_full)\n",
    "# normalize between 0 and 1\n",
    "ksp_full = (ksp_full - np.min(ksp_full)) / (np.max(ksp_full) - np.min(ksp_full))\n",
    "\n",
    "x, y, z = ksp_full.shape\n",
    "\n",
    "# Create axis\n",
    "axes = [x, y, z]\n",
    "\n",
    "mid_x = ksp_full[x//2, :, :]\n",
    "mid_y = ksp_full[:, y//2, :]\n",
    "mid_z = ksp_full[:, :, z//2]\n",
    "\n",
    "ksp_full[0, :, :] = mid_x\n",
    "ksp_full[-1, :, : ] = mid_x\n",
    "ksp_full[:, 0, :] = mid_y\n",
    "ksp_full[:, -1, :] = mid_y\n",
    "ksp_full[:, :, 0] = mid_z\n",
    "ksp_full[:, :, -1] = mid_z\n",
    "\n",
    "# set inner part to zero\n",
    "ksp_full[1:-1, 1:-1, 1:-1] = 0\n",
    "\n",
    "# Create Data\n",
    "data = np.zeros(axes)\n",
    "data[np.where(ksp_full != 0)] = 1\n",
    "data.astype(bool)\n",
    "\n",
    "# ksp_full[-1, -1, :] = 0 \n",
    "# ksp_full[-1,  0, :] = 0\n",
    "# ksp_full[0,  -1, :] = 0 \n",
    "# ksp_full[0,   0, :] = 0\n",
    "\n",
    "# ksp_full[0,  :, -1] = 0 \n",
    "# ksp_full[0,   :, 0] = 0 \n",
    "# ksp_full[-1, :, -1] = 0 \n",
    "# ksp_full[-1,  :, 0] = 0 \n",
    "\n",
    "# ksp_full[:, -1, -1] = 0 \n",
    "# ksp_full[:, -1,  0] = 0\n",
    "# ksp_full[:, 0,  -1] = 0 \n",
    "# ksp_full[:, 0,   0] = 0\n",
    "\n",
    "# Control colour\n",
    "colors = np.empty(axes + [3], dtype=np.float32)\n",
    "\n",
    "print(colors.shape)\n",
    "b_x, b_y, b_z = np.where(ksp_full !=0)\n",
    "\n",
    "colors[b_x, b_y,b_z , 0] = ksp_full[b_x, b_y,b_z]\n",
    "colors[b_x, b_y,b_z , 1] = ksp_full[b_x, b_y,b_z]\n",
    "colors[b_x, b_y,b_z , 2] = ksp_full[b_x, b_y,b_z]\n",
    "\n",
    "\n",
    "print(np.count_nonzero(colors), np.count_nonzero(data))\n",
    "\n",
    "# Plot figure\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d', proj_type = 'ortho')\n",
    "ax.voxels(data, facecolors=colors, shade=False)\n",
    "plt.grid(b=None) # Hide grid lines\n",
    "plt.axis('off') # Hide axes ticks\n",
    "ax.view_init(elev=20, azim=95, ) # Set the view angle\n",
    "# ax.view_init(elev=17, azim=-80, roll = 2.1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ksp = f'../../results/kspacesampling/final/ksp/u_kspace_M1_hr'\n",
    "\n",
    "ksp_sparse = np.abs(cfl.readcfl(path_ksp).squeeze()[:, :, :, 0,  0])\n",
    "ksp_sparse = adjust_image_size_centered(ksp_sparse[np.newaxis, ... ], (1, *ksp_full.shape)).squeeze()\n",
    "\n",
    "print('min/max', np.min(ksp_sparse), np.max(ksp_sparse))\n",
    "ksp_sparse +=1\n",
    "#normalisera\n",
    "ksp_sparse = np.log(ksp_sparse)\n",
    "print('min/max', np.min(ksp_sparse), np.max(ksp_sparse))\n",
    "# normalize between 0 and 1\n",
    "ksp_sparse = (ksp_sparse - np.min(ksp_sparse)) / (np.max(ksp_sparse) - np.min(ksp_sparse))\n",
    "print('min/max', np.min(ksp_sparse), np.max(ksp_sparse))\n",
    "\n",
    "x, y, z = ksp_sparse.shape\n",
    "\n",
    "# Create axis\n",
    "axes = [x, y, z]\n",
    "\n",
    "mid_x = ksp_sparse[x//2, :, :]\n",
    "mid_y = ksp_sparse[:, y//2, :]\n",
    "mid_z = ksp_sparse[:, :, z//2]\n",
    "\n",
    "ksp_sparse[0, :,  :] = mid_x\n",
    "ksp_sparse[-1, :, :] = mid_x\n",
    "ksp_sparse[:, 0,  :] = mid_y\n",
    "ksp_sparse[:, -1, :] = mid_y\n",
    "ksp_sparse[:, :,  0] = mid_z\n",
    "ksp_sparse[:, :, -1] = mid_z\n",
    "\n",
    "# set inner part of cube to zero\n",
    "ksp_sparse[1:-1, 1:-1, 1:-1] = 0\n",
    "\n",
    "# Create Data\n",
    "data = np.zeros(ksp_sparse.shape)\n",
    "data[0, :,  :] = 1\n",
    "data[-1, :, :] = 1\n",
    "data[:, 0,  :] = 1\n",
    "data[:, -1, :] = 1\n",
    "data[:, :,  0] = 1\n",
    "data[:, :, -1] = 1\n",
    "\n",
    "\n",
    "\n",
    "# Control colour\n",
    "colors = np.empty(axes + [3], dtype=np.float32)\n",
    "\n",
    "print(colors.shape)\n",
    "b_x, b_y, b_z = np.where(data == 1)\n",
    "data.astype(bool)\n",
    "\n",
    "print(np.count_nonzero(colors), np.count_nonzero(data), np.count_nonzero(ksp_sparse))\n",
    "\n",
    "colors[b_x, b_y, b_z, 0] = ksp_sparse[b_x, b_y, b_z]\n",
    "colors[b_x, b_y, b_z, 1] = ksp_sparse[b_x, b_y, b_z]\n",
    "colors[b_x, b_y, b_z, 2] = ksp_sparse[b_x, b_y, b_z]\n",
    "\n",
    "print(np.count_nonzero(colors), np.count_nonzero(data), np.count_nonzero(ksp_sparse))\n",
    "\n",
    "# Plot figure\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d', proj_type = 'ortho')\n",
    "ax.voxels(data, facecolors=colors, shade=False)\n",
    "plt.grid(b=None) # Hide grid lines\n",
    "plt.axis('off')  # Hide axes ticks\n",
    "ax.view_init(elev=20, azim=5, roll=1.3) # Set the view angle\n",
    "# ax.view_init(elev=17, azim=-80, roll = 2.1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(mid_x)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(mid_y)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(mid_z)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cfl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m path_ksp \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../results/kspacesampling/final/ksp/u_kspace_M1_lr\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m ksp_sparse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(\u001b[43mcfl\u001b[49m\u001b[38;5;241m.\u001b[39mreadcfl(path_ksp)\u001b[38;5;241m.\u001b[39msqueeze()[:, :, :, \u001b[38;5;241m0\u001b[39m,  \u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      4\u001b[0m ksp_sparse \u001b[38;5;241m=\u001b[39m adjust_image_size_centered(ksp_sparse[np\u001b[38;5;241m.\u001b[39mnewaxis, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m ], (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39mksp_full\u001b[38;5;241m.\u001b[39mshape))\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[0;32m      5\u001b[0m readout_lines \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(ksp_sparse\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cfl' is not defined"
     ]
    }
   ],
   "source": [
    "path_ksp = f'../../results/kspacesampling/final/ksp/u_kspace_M1_lr'\n",
    "\n",
    "ksp_sparse = np.abs(cfl.readcfl(path_ksp).squeeze()[:, :, :, 0,  0])\n",
    "ksp_sparse = adjust_image_size_centered(ksp_sparse[np.newaxis, ... ], (1, *ksp_full.shape)).squeeze()\n",
    "readout_lines = np.zeros(ksp_sparse.shape)\n",
    "readout_lines[np.where(ksp_sparse != 0)] = 1\n",
    "\n",
    "x, y, z = ksp_sparse.shape\n",
    "\n",
    "# Create axis\n",
    "axes = [x, y, z]\n",
    "\n",
    "# set inner part of cube to zero\n",
    "ksp_sparse[1:-1, 1:-1, 1:-1] = 0\n",
    "\n",
    "# Create Data\n",
    "data = np.zeros(ksp_sparse.shape)\n",
    "data[np.where(readout_lines == 1)] = 1\n",
    "\n",
    "# Control colour\n",
    "colors = np.empty(axes + [1], dtype=np.float32)\n",
    "\n",
    "print(colors.shape)\n",
    "b_x, b_y, b_z = np.where(data == 1)\n",
    "data.astype(bool)\n",
    "\n",
    "print(np.count_nonzero(colors), np.count_nonzero(data), np.count_nonzero(ksp_sparse))\n",
    "\n",
    "colors[b_x, b_y, b_z, 0] = 'red'\n",
    "\n",
    "print(np.count_nonzero(colors), np.count_nonzero(data), np.count_nonzero(ksp_sparse))\n",
    "\n",
    "# Plot figure\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d', proj_type = 'ortho')\n",
    "ax.voxels(data, facecolors=colors, shade=False)\n",
    "plt.grid(b=None) # Hide grid lines\n",
    "plt.axis('off')  # Hide axes ticks\n",
    "ax.view_init(elev=20, azim=5, roll=1.3) # Set the view angle\n",
    "# ax.view_init(elev=17, azim=-80, roll = 2.1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(mid_x)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(mid_y)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(mid_z)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "path_csm = f'../../results/kspacesampling/csm/csm_64_126_resized'\n",
    "csm = cfl.readcfl(path_csm)\n",
    "\n",
    "csm_1 = np.abs(csm[..., 2])\n",
    "csm_1 = adjust_image_size_centered(np.expand_dims(csm_1, -1), (*ksp_full.shape, 1)).squeeze()\n",
    "\n",
    "# set middle to zero\n",
    "csm_1[1:-1, 1:-1, 1:-1] = 0\n",
    "\n",
    "# normalisera\n",
    "csm_1 /= np.max(csm_1)\n",
    "\n",
    "x, y, z = csm_1.shape\n",
    "\n",
    "# Create axis\n",
    "axes = [x, y, z]\n",
    "\n",
    "# Control colour\n",
    "colors = np.empty(axes + [3], dtype=np.float32)\n",
    "\n",
    "b_x, b_y, b_z = np.where(csm_1 !=0)\n",
    "\n",
    "colors[b_x, b_y,b_z , 0] = csm_1[b_x, b_y,b_z]\n",
    "colors[b_x, b_y,b_z , 1] = csm_1[b_x, b_y,b_z]\n",
    "colors[b_x, b_y,b_z , 2] = csm_1[b_x, b_y,b_z]\n",
    "\n",
    "data = np.zeros(axes)\n",
    "data[np.where(csm_1 != 0 )] = 1\n",
    "data.astype(bool)\n",
    "\n",
    "print(colors.shape)\n",
    "\n",
    "print(np.count_nonzero(colors), np.count_nonzero(data))\n",
    "\n",
    "print('Plot figure ..')\n",
    "# Plot figure\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d', proj_type = 'ortho')\n",
    "ax.voxels(data, facecolors=colors, shade=False)\n",
    "plt.grid(b=None) # Hide grid lines\n",
    "plt.axis('off') # Hide axes ticks\n",
    "ax.view_init(elev=20, azim=95, roll=1.3) # Set the view angle\n",
    "# Set the view angle\n",
    "# ax.view_init(elev=17, azim=-80, roll = 2.1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_data = np.random.rand(*csm_1.shape)\n",
    "\n",
    "# Control colour\n",
    "colors = np.empty(axes + [3], dtype=np.float32)\n",
    "\n",
    "print(colors.shape)\n",
    "\n",
    "b_x, b_y, b_z = np.where(csm_1 !=0)\n",
    "\n",
    "colors[b_x, b_y,b_z , 0] = noise_data[b_x, b_y,b_z]\n",
    "colors[b_x, b_y,b_z , 1] = noise_data[b_x, b_y,b_z]\n",
    "colors[b_x, b_y,b_z , 2] = noise_data[b_x, b_y,b_z]\n",
    "\n",
    "data = np.zeros(axes)\n",
    "data[np.where(csm_1 != 0 )] = 1\n",
    "data.astype(bool)\n",
    "\n",
    "# Plot figure\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Voxels is used to customizations of the\n",
    "# sizes, positions and colors.\n",
    "ax.voxels(data, facecolors=colors)\n",
    "\n",
    "# Hide grid lines\n",
    "plt.grid(b=None)\n",
    "\n",
    "# Hide axes ticks\n",
    "plt.axis('off')\n",
    "# Set the view angle\n",
    "ax.view_init(elev=17, azim=-80, roll = 2.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "orig_data = f'/mnt/c/Users/piacal/Code/SuperResolution4DFlowMRI/Temporal4DFlowNet/data/CARDIAC/M1_2mm_step2_static_dynamic.h5'\n",
    "path_lr = \"../../results/kspacesampling/final/output_M1_lr.h5\"\n",
    "path_hr_i10 = \"../../results/kspacesampling/final/output_M1_hr_i10.h5\"\n",
    "path_hr_l2 = \"../../results/kspacesampling/final/output_M1_hr_l2.h5\"\n",
    "path_hr_i10_l2 = \"../../results/kspacesampling/final/output_M1_hr_l2_i10.h5\"\n",
    "path_hr_fpqr = \"../../results/kspacesampling/final/output_M1_hr_fpqr.h5\"\n",
    "path_ksp = f'../../results/kspacesampling/final/ksp/u_kspace_M1_hr'\n",
    "\n",
    "\n",
    "\n",
    "with h5py.File(orig_data, 'r') as hf:\n",
    "    mask = np.array(hf['mask'])\n",
    "    u_orig  = np.array(hf['u'])\n",
    "\n",
    "with h5py.File(path_hr_fpqr, 'r') as hf:\n",
    "    u_hr_fpqr = np.array(hf['u'])\n",
    "\n",
    "with h5py.File(path_hr_i10, 'r') as hf:\n",
    "    u_hr_i10 = np.array(hf['u'])\n",
    "\n",
    "with h5py.File(path_hr_l2, 'r') as hf:\n",
    "    u_hr_l2 = np.array(hf['u'])\n",
    "\n",
    "with h5py.File(path_hr_i10_l2, 'r') as hf:\n",
    "    u_hr_l2_i10 = np.array(hf['u'])\n",
    "\n",
    "with h5py.File(path_lr, 'r') as hf:\n",
    "    u_lr = np.array(hf['u'])\n",
    "\n",
    "# u_ksp_sampled = cfl.readcfl(path_ksp).squeeze().transpose(4, 0, 1, 2, 3 )\n",
    "# u_ksp_sampled = u_ksp_sampled[:, :, :, :, 0]\n",
    "# u_recon = np.angle(fft_fcts.centered_kspace_to_complex_img(u_ksp_sampled))/np.pi * (np.max(u_orig))\n",
    "\n",
    "# print(np.max(u_recon), np.min(u_recon))\n",
    "# plt.imshow(u_recon[20, :, :])\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "def create_temporal_comparison_gif_single(idx, data,  path,title= '',  fps = 10):\n",
    "\n",
    "    min_v = np.min(u_orig[:, idx, :, :])\n",
    "    max_v = np.max(u_orig[:, idx, :, :])\n",
    "\n",
    "    N_frames = data.shape[0]\n",
    "    print(path, 'nframes:', data.shape[0])\n",
    "    fig = plt.figure(frameon=False)\n",
    "    im1 = plt.imshow(data[0, idx, :, :],interpolation='none' , vmin=min_v, vmax=max_v)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    #fig.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=None, hspace=None)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    #initialization function: plot the background of each frame\n",
    "    def init():\n",
    "        im1.set_data(np.random.random((5,5)))\n",
    "        return [im1]\n",
    "\n",
    "    # animation function.  This is called sequentially\n",
    "    def animate(i):\n",
    "        im1.set_array(data[i, idx, :, :])\n",
    "        return [im1]\n",
    "\n",
    "    anim = animation.FuncAnimation(fig,animate, init_func=init, frames = N_frames, interval = 100) # in ms)\n",
    "    anim.save(f'{path}.gif', fps=fps)\n",
    "\n",
    "\n",
    "create_temporal_comparison_gif_single(20, u_hr_l2_i10,'../../results/kspacesampling/final/output_M1_hr_u_l2_i10' ,title=  'HR i10 L2', fps =20 )\n",
    "create_temporal_comparison_gif_single(20, u_hr_i10,'../../results/kspacesampling/final/output_M1_hr_u_i10' , title='HR i10',  fps =20 )\n",
    "create_temporal_comparison_gif_single(20, u_hr_l2,'../../results/kspacesampling/final/output_M1_hr_u_L2' , title='HR L2',  fps =20 )\n",
    "create_temporal_comparison_gif_single(20, u_orig,'../../results/kspacesampling/final/output_M1_hr_u_orig' , title='HR CFD orig',  fps =20 )\n",
    "create_temporal_comparison_gif_single(20, u_hr_fpqr,'../../results/kspacesampling/final/output_M1_hr_u_fpqr' , title='HR f pqr',  fps =20 )\n",
    "# create_temporal_comparison_gif_single(20, u_lr,'../../results/kspacesampling/final/output_M1_lr_u' , fps =10 )\n",
    "# create_temporal_comparison_gif_single(20, u_recon,'../../results/kspacesampling/final/output_M1_reconstr_u_hr' , fps =10 )\n",
    "# create_temporal_comparison_gif_single(20, u_recon*adjust_image_size(mask, u_recon.shape),'../../results/kspacesampling/final/output_M1_reconstr_u_hr_masked' , fps =10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check on compressed sensing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_image_size(image, new_shape):\n",
    "    \"\"\"\n",
    "    Adjust the size of the image to the new shape, assumes 4D image\n",
    "    \"\"\"\n",
    "    old_shape = image.shape\n",
    "    \n",
    "    padding = []\n",
    "\n",
    "    # pad the image\n",
    "    for i in range(len(new_shape)):\n",
    "        # diff positive for padding and negative for cropping\n",
    "        diff = new_shape[i] - old_shape[i]\n",
    "        \n",
    "        if diff > 0:\n",
    "            # pad the image\n",
    "            pad_before = diff // 2\n",
    "            pad_after = diff - pad_before\n",
    "            padding.append((pad_before, pad_after))\n",
    "        else:\n",
    "            # no adjustment needed\n",
    "            padding.append((0, 0))\n",
    "\n",
    "        #cropping\n",
    "        if diff < 0:\n",
    "            t_mid = int(old_shape[i] // 2)\n",
    "            cropr = int(np.floor(abs(new_shape[i]) / 2))\n",
    "            cropl = int(np.ceil(abs(new_shape[i]) / 2))\n",
    "            if i == 0:\n",
    "                image = image[t_mid - cropl:t_mid + cropr, :, :, :]\n",
    "            elif i == 1:\n",
    "                image = image[:, t_mid - cropl:t_mid + cropr, :, :]\n",
    "            elif i == 2:\n",
    "                image = image[:, :, t_mid - cropl:t_mid + cropr, :]\n",
    "            elif i == 3:\n",
    "                image = image[:, :, :, t_mid - cropl:t_mid + cropr]\n",
    "\n",
    "    # pad the image\n",
    "    new_image = np.pad(image, padding, mode='constant', constant_values=0)\n",
    "\n",
    "    print(f\"Adjusted image size from {old_shape} to {new_image.shape}\")\n",
    "    return new_image\n",
    "\n",
    "# get phase image\n",
    "def phase_norm_to_vel(phase, min_vel, max_vel):\n",
    "    return (phase + np.pi) / np.pi * (max_vel - min_vel) + min_vel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "data_models = ['M1', 'M2', 'M3', 'M4', 'M5', 'M6']\n",
    "vel = ['u', 'v', 'w']\n",
    "\n",
    "idx = np.index_exp[0, 20, :, :]\n",
    "\n",
    "#output_{vel}_{model_name}_{res}\n",
    "# load data\n",
    "for m in data_models:\n",
    "    orig_model = f'/mnt/c/Users/piacal/Code/SuperResolution4DFlowMRI/Temporal4DFlowNet/data/CARDIAC/{m}_2mm_step2_static_dynamic.h5'\n",
    "    orig_lr =  f'/mnt/c/Users/piacal/Code/SuperResolution4DFlowMRI/Temporal4DFlowNet/data/CARDIAC/{m}_2mm_step2_static_dynamic_noise.h5'\n",
    "\n",
    "    for v in vel:\n",
    "        with h5py.File(orig_model, 'r') as hf:\n",
    "            vel_orig = np.array(hf[v])\n",
    "            mask = np.array(hf['mask'])\n",
    "            t, x, y, z = vel_orig.shape \n",
    "        \n",
    "        with h5py.File(orig_lr, 'r') as hf:\n",
    "            lr_orig = np.array(hf[v])\n",
    "\n",
    "        path = f'../../results/kspacesampling/output_{v}_{m}'\n",
    "        lr = cfl.readcfl(f'{path}_lr').squeeze().transpose(3, 0, 1,2)\n",
    "        hr = np.ones_like(vel_orig)#cfl.readcfl(f'{path}_hr').squeeze().transpose(3, 0, 1,2)\n",
    "\n",
    "        lr = adjust_image_size(lr, (lr.shape[0], x, y, z))\n",
    "        hr = adjust_image_size(hr, (hr.shape[0], x, y, z))\n",
    "\n",
    "        lr = phase_norm_to_vel(np.angle(lr) - np.pi, vel_orig.min(), vel_orig.max())\n",
    "        hr = phase_norm_to_vel(np.angle(hr), vel_orig.min(), vel_orig.max())\n",
    "        print(np.sum(np.abs(hr)))\n",
    "        \n",
    "        plt.figure(figsize = (10, 10))\n",
    "        plt.subplot(1, 5, 1)\n",
    "        plt.imshow(lr[idx])\n",
    "        plt.title(f'{m}_{v} - lr')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 5, 2)\n",
    "        plt.imshow(lr[idx]*mask[idx])\n",
    "        plt.title(f'{m}_{v} - lr fluid ')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 5, 3)\n",
    "        plt.imshow(lr_orig[idx]*mask[idx])\n",
    "        plt.title(f'{m}_{v} - lr fluid orig.')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 5, 4)\n",
    "        plt.imshow(hr[idx])\n",
    "        plt.title(f'{m}_{v} - hr')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 5, 5)\n",
    "        plt.imshow(vel_orig[idx])\n",
    "        plt.title(f'{m}_{v} - orig')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        print(f'{m}_{v} - lr: {lr.shape} - hr: {hr.shape}')\n",
    "        psnr_u = peak_signal_to_noise_ratio(vel_orig[::2], lr)\n",
    "        psnr_u_fluid = peak_signal_to_noise_ratio(vel_orig[::2], lr*mask[::2])\n",
    "        print('peak snr', psnr_u.round(3), 'psnr (fluid region)',  psnr_u_fluid.round(3))\n",
    "        psnr_u_orig = peak_signal_to_noise_ratio(vel_orig, lr_orig)\n",
    "        psnr_u_fluid_orig = peak_signal_to_noise_ratio(vel_orig, lr_orig*mask)\n",
    "        print('peak snr orig', psnr_u_orig.round(3), 'psnr (fluid region) orig',  psnr_u_fluid_orig.round(3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 'M1'\n",
    "orig_model = f'../../data/CARDIAC/{m}_2mm_step2_static_dynamic.h5'\n",
    "v = 'u'\n",
    "with h5py.File(orig_model, 'r') as hf:\n",
    "    vel_orig = np.array(hf[v])\n",
    "    mask = np.array(hf['mask'])\n",
    "    t, x, y, z = vel_orig.shape \n",
    "\n",
    "k_space = fft_fcts.velocity_img_to_centered_kspace(vel_orig, mask, venc = np.max(vel_orig))\n",
    "plt.imshow(np.abs(k_space[0, 12, :, :]), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "sigma = 6\n",
    "complex_noise = np.random.normal(0, sigma, k_space.shape) + 1j * np.random.normal(0, sigma, k_space.shape)\n",
    "\n",
    "plt.imshow(np.abs(complex_noise[0, 12, :, :]), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "sample_mask_random = np.random.randint(0, 10, size=vel_orig.shape)\n",
    "sample_mask_random[np.where(sample_mask_random > 1)] = 0\n",
    "plt.imshow(sample_mask_random[0, 12, :, :], cmap='gray')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "path_model = f'/mnt/c/Users/piacal/Code/SuperResolution4DFlowMRI/Temporal4DFlowNet/data/CARDIAC/M1_2mm_step2_static_dynamic.h5'\n",
    "path_ksp = f'../../results/kspacesampling/final/ksp/u_kspace_M1_hr'\n",
    "\n",
    "\n",
    "with h5py.File(orig_model, 'r') as hf:\n",
    "    u = np.array(hf['u'])\n",
    "    mask = np.array(hf['mask'])\n",
    "\n",
    "\n",
    "venc = np.max(u)\n",
    "cmp_img = np.multiply(mask, (1j*(u/venc*np.pi)))\n",
    "ksp_full = fft_fcts.complex_image_to_centered_kspace(cmp_img)\n",
    "\n",
    "t, x, y, z = ksp_full.shape\n",
    "\n",
    "plt.imshow(np.abs(ksp_full[0, x//2, :, :]), cmap = 'Greys_r')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(np.abs(ksp_full[0, :, y//2, :]), cmap = 'Greys_r')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(np.abs(ksp_full[0, :, :, z//2]), cmap = 'Greys_r')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "u_ksp_sampled = cfl.readcfl(path_ksp).squeeze().transpose(4, 0, 1, 2, 3 )\n",
    "u_ksp_sampled = np.abs(u_ksp_sampled[0, :, :, :, 0])\n",
    "# print(u.shape, u_ksp_sampled.shape)\n",
    "x_k, y_k, z_k = u_ksp_sampled.shape\n",
    "\n",
    "plt.imshow(u_ksp_sampled[x_k//2, :, :], cmap = 'Greys_r')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(u_ksp_sampled[:, y_k//2, :], cmap = 'Greys_r')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(u_ksp_sampled[:, :, z_k//2], cmap = 'Greys_r')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D \n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "# Generate coordinates for the k-space matrix\n",
    "x, y, z = np.indices(u_ksp_sampled.shape)\n",
    "norm = plt.Normalize(vmin=np.min(np.abs(u_ksp_sampled)), vmax=np.max(np.abs(u_ksp_sampled)))\n",
    "# Create the figure and the 3D axes\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Flatten the arrays for easier plotting\n",
    "x = x.flatten()\n",
    "y = y.flatten()\n",
    "z = z.flatten()\n",
    "values = np.abs(u_ksp_sampled).flatten()\n",
    "\n",
    "# Plot each point in the k-space\n",
    "sc = ax.scatter(x, y, z, c=values, cmap='Greys_r', alpha=norm(values))\n",
    "\n",
    "# Add color bar for reference\n",
    "cbar = plt.colorbar(sc, ax=ax, shrink=0.5, aspect=5)\n",
    "cbar.set_label('Intensity')\n",
    "\n",
    "# Set labels\n",
    "ax.set_xlabel('kx')\n",
    "ax.set_ylabel('ky')\n",
    "ax.set_zlabel('kz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test norm 0 and 2 pi\n",
    "orig_model = f'/mnt/c/Users/piacal/Code/SuperResolution4DFlowMRI/Temporal4DFlowNet/data/CARDIAC/{m}_2mm_step2_static_dynamic.h5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vel_to_phase(vel, venc):\n",
    "    return (vel/venc)*np.pi + np.pi\n",
    "\n",
    "def phase_to_vel(phase, venc):\n",
    "    return ((phase- np.pi)/np.pi)*venc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 'M1'\n",
    "orig_model  =  f'/mnt/c/Users/piacal/Code/SuperResolution4DFlowMRI/Temporal4DFlowNet/data/CARDIAC/{m}_2mm_step2_static_dynamic.h5'\n",
    "\n",
    "v = 'u'\n",
    "with h5py.File(orig_model, 'r') as hf:\n",
    "    vel = np.array(hf[v])\n",
    "    magn = np.array(hf['mask'])\n",
    "\n",
    "venc = np.max(np.abs(vel))\n",
    "vel = vel/venc * np.pi + np.pi\n",
    "\n",
    "complex_img =  np.multiply(magn, np.exp(1j * vel) )\n",
    "kspace = fft_fcts.complex_image_to_centered_kspace(complex_img)\n",
    "rev_c = fft_fcts.centered_kspace_to_complex_img(kspace)\n",
    "\n",
    "idxs = np.index_exp[0, 20, :, :]\n",
    "min_v = -np.pi\n",
    "max_v = np.pi\n",
    "\n",
    "print('min/max vel', np.min(vel), np.max(vel))\n",
    "print('min/max compl img', np.min(np.angle(complex_img)), np.max(np.angle(complex_img)))\n",
    "print('min/max compl rev', np.min(np.angle(rev_c)), np.max(np.angle(rev_c)))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(magn[idxs]*np.angle(complex_img[idxs]), vmin= min_v, vmax=max_v)\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(magn[idxs]*np.angle(rev_c[idxs]), vmin=min_v, vmax=max_v)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(vel[idxs], vmin=min_v, vmax=max_v)\n",
    "\n",
    "print(np.allclose(complex_img*magn, rev_c*magn, atol=1e-10), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "m = 'M1'\n",
    "orig_model  =  f'/mnt/c/Users/piacal/Code/SuperResolution4DFlowMRI/Temporal4DFlowNet/data/CARDIAC/{m}_2mm_step2_static_dynamic.h5'\n",
    "orig_lr     =  f'/mnt/c/Users/piacal/Code/SuperResolution4DFlowMRI/Temporal4DFlowNet/data/CARDIAC/{m}_2mm_step2_static_dynamic_noise.h5'\n",
    "\n",
    "v = 'u'\n",
    "with h5py.File(orig_model, 'r') as hf:\n",
    "    vel_orig = np.array(hf[v])\n",
    "    venc = np.max(np.asarray(hf[f'{v}_max']))\n",
    "    venc = 3.037533\n",
    "    print('venc', venc) # 3.037533\n",
    "    mask = np.array(hf['mask'])\n",
    "    t, x, y, z = vel_orig.shape \n",
    "\n",
    "with h5py.File(orig_lr, 'r') as hf:\n",
    "    lr_orig = np.array(hf[v])\n",
    "\n",
    "path_hr = f'../../results/kspacesampling/oldresults/output_M1_hr/output_{v}_{m}'\n",
    "path_lr = f'../../results/kspacesampling/final/output_{v}_{m}'\n",
    "\n",
    "lr = cfl.readcfl(f'{path_lr}_lr').squeeze().transpose(3, 0, 1,2)\n",
    "hr = cfl.readcfl(f'{path_hr}_hr').squeeze().transpose(3, 0, 1,2)\n",
    "\n",
    "lr = adjust_image_size(lr, (lr.shape[0], x, y, z))\n",
    "hr = adjust_image_size(hr, (hr.shape[0], x, y, z))\n",
    "\n",
    "lr = np.angle(lr)\n",
    "hr = np.angle(hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# denormalize -> phase to vel\n",
    "\n",
    "print('min and max of lr ', lr.min(), lr.max())\n",
    "lr_norm1 = (lr)/np.pi*venc#phase_to_vel(np.angle(lr), venc)#phase_norm_to_vel(np.angle(lr), vel_orig.min(), vel_orig.max())\n",
    "hr_norm1 = phase_norm_to_vel(hr - np.pi, vel_orig.min(), vel_orig.max())\n",
    "\n",
    "lr_norm2 = ((lr- np.pi)/np.pi)*venc\n",
    "lr_norm3 = phase_norm_to_vel(lr, vel_orig.min(), vel_orig.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_range_lr = np.arange(0, t, 2)\n",
    "plt.plot(np.mean(lr_orig, axis=(1, 2, 3), where=mask.astype(bool)), label='lr orig')\n",
    "plt.plot(np.mean(vel_orig, axis=(1, 2, 3), where=mask.astype(bool)),'--',  label='orig')\n",
    "plt.plot(t_range_lr, np.mean(lr_norm1, axis=(1, 2, 3), where=mask.astype(bool)[::2]), label='lr1 cs')\n",
    "plt.plot(t_range_lr, np.mean(lr_norm2, axis=(1, 2, 3), where=mask.astype(bool)[::2]), label='lr2 cs')\n",
    "plt.plot(t_range_lr, np.mean(lr_norm3, axis=(1, 2, 3), where=mask.astype(bool)[::2]), label='lr3 cs')\n",
    "plt.plot(np.mean(hr_norm1, axis=(1, 2, 3), where=mask.astype(bool)), label='hr cs')  \n",
    "plt.legend()\n",
    "print('diff', np.mean(lr, axis=(1, 2, 3), where=mask.astype(bool)[::2]) -  np.mean(vel_orig[::2], axis=(1, 2, 3), where=mask.astype(bool)[::2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "idx = np.index_exp[:, 40, 25, 30]\n",
    "t_range_lr = np.arange(0, vel_orig.shape[0], 2)\n",
    "plt.plot(t_range_lr, lr_norm1[idx], label = 'lr1 cs')\n",
    "# plt.plot(t_range_lr, lr_norm2[idx], label = 'lr2 cs')\n",
    "# plt.plot(t_range_lr, lr_norm3[idx], label = 'lr3 cs')\n",
    "# plt.plot(hr[idx], label = 'hr cs')\n",
    "plt.plot(vel_orig[idx], label = 'orig')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "max_vel = np.max(hr*mask)\n",
    "min_vel = np.min(hr*mask)\n",
    "idx_show = np.index_exp[2, 40, :, :]\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(lr_norm1[idx_show]*mask[idx_show], vmin=min_vel, vmax = max_vel)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(vel_orig[idx_show]*mask[idx_show], vmin=min_vel, vmax = max_vel)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow((hr[idx_show] - lr_norm1[idx_show])*mask[idx_show])\n",
    "plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "max_vel = np.max(vel_orig*mask)-0.1\n",
    "min_vel = np.min(vel_orig*mask)+0.1\n",
    "\n",
    "@widgets.interact(frame=(0, hr.shape[0]-1), x = (0, hr.shape[1]-1), axis=[0, 1, 2])\n",
    "def f(frame=5, x = 10,  axis = 0):\n",
    "    plt.figure(figsize=(7,7))\n",
    "    N = 3\n",
    "    idxs = get_indices(frame,axis, x)\n",
    "    idx_lr = get_indices(frame//2,axis, x)\n",
    "\n",
    "\n",
    "    plt.subplot(1, N, 1)\n",
    "    plt.imshow(lr_norm1[idx_lr]*mask[idxs],  vmin = min_vel, vmax = max_vel, cmap='viridis') #vmin = min_vel, vmax = max_vel,\n",
    "    plt.title('lr cs')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, N, 2)\n",
    "    plt.imshow(vel_orig[idxs]*mask[idxs],  vmin = min_vel, vmax = max_vel, cmap='viridis')\n",
    "    plt.title('orig cs')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, N, 3)\n",
    "    plt.imshow((hr[idxs]-lr_norm1[idx_lr]) *mask[idxs],  vmin = min_vel, vmax = max_vel, cmap='viridis')\n",
    "    diff_max = np.max(np.abs((hr[idxs]-lr_norm1[idx_lr]) *mask[idxs]))\n",
    "    plt.title(f'diff max {diff_max:.4f} m/s')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# delete this later\n",
    "m = 'M1'\n",
    "orig_model = f'/mnt/c/Users/piacal/Code/SuperResolution4DFlowMRI/Temporal4DFlowNet/data/CARDIAC/{m}_2mm_step2_static_dynamic.h5'\n",
    "orig_lr =  f'/mnt/c/Users/piacal/Code/SuperResolution4DFlowMRI/Temporal4DFlowNet/data/CARDIAC/{m}_2mm_step2_static_dynamic_noise.h5'\n",
    "\n",
    "v = 'u'\n",
    "with h5py.File(orig_model, 'r') as hf:\n",
    "    vel_orig = np.array(hf[v])\n",
    "    mask = np.array(hf['mask'])\n",
    "    t, x, y, z = vel_orig.shape \n",
    "\n",
    "with h5py.File(orig_lr, 'r') as hf:\n",
    "    lr_orig = np.array(hf[v])\n",
    "\n",
    "path_hr = f'../../results/kspacesampling/output_M1_hr/output_{v}_{m}'\n",
    "path_lr = f'../../results/kspacesampling/output_{v}_{m}'\n",
    "lr = cfl.readcfl(f'{path_lr}_lr').squeeze().transpose(3, 0, 1,2)\n",
    "hr = cfl.readcfl(f'{path_hr}_hr').squeeze().transpose(3, 0, 1,2)#np.ones_like(vel_orig)#cfl.readcfl(f'{path}_hr').squeeze().transpose(3, 0, 1,2)\n",
    "hr2 =  cfl.readcfl(f'../../results/kspacesampling/output_M1_hr_nocoilsens').squeeze().transpose(3, 0, 1,2)\n",
    "\n",
    "lr = adjust_image_size(lr, (lr.shape[0], x, y, z))\n",
    "hr = adjust_image_size(hr, (hr.shape[0], x, y, z))\n",
    "hr2 = adjust_image_size(hr2, (hr2.shape[0], x, y, z))\n",
    "\n",
    "lr = phase_norm_to_vel(np.angle(lr) - np.pi, vel_orig.min(), vel_orig.max())\n",
    "hr = phase_norm_to_vel(np.angle(hr) - np.pi, vel_orig.min(), vel_orig.max())\n",
    "hr2 = phase_norm_to_vel(np.angle(hr2) - np.pi, vel_orig.min(), vel_orig.max())\n",
    "print(np.sum(np.abs(hr)))\n",
    "\n",
    "t_range_lr = np.arange(0, t, 2)\n",
    "plt.plot(np.mean(lr_orig, axis=(1, 2, 3), where=mask.astype(bool)), label='lr orig')\n",
    "plt.plot(np.mean(vel_orig, axis=(1, 2, 3), where=mask.astype(bool)),'--',  label='orig')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.index_exp[:, 40, 25, 30]\n",
    "t_range_lr = np.arange(0, vel_orig.shape[0], 2)\n",
    "plt.plot(t_range_lr, lr[idx], label = 'lr cs')\n",
    "plt.plot(hr[idx], label = 'hr cs')\n",
    "plt.plot(hr2[idx], label = 'hr cs no coil sensitivity')\n",
    "plt.plot(vel_orig[idx], label = 'orig')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complex_image_to_centered_kspace(complex_img):\n",
    "\n",
    "    if len(complex_img.shape) == 3:\n",
    "        axes = (0, 1, 2)\n",
    "    elif len(complex_img.shape) == 4:\n",
    "        axes = (1, 2, 3)\n",
    "    else:\n",
    "        print(\"Error: Unsupported number of dimensions, please extend function to \", len(complex_img.shape), \" dimensions.\")\n",
    "\n",
    "    # ifftshift\n",
    "    complex_img = np.fft.ifftshift(complex_img, axes=axes)\n",
    "\n",
    "    # fft\n",
    "    imgfft = np.fft.fftn(complex_img, axes = axes)\n",
    "\n",
    "    # shift img to center\n",
    "    imgfft = np.fft.fftshift(imgfft, axes=axes)\n",
    "    return imgfft\n",
    "\n",
    "def centered_kspace_to_complex_img(imgfft):\n",
    "    if len(imgfft.shape) == 3:\n",
    "        axes = (0, 1, 2)\n",
    "    elif len(imgfft.shape) == 4:\n",
    "        axes = (1, 2, 3)\n",
    "    else:\n",
    "        print(\"Error: Unsupported number of dimensions, please extend function to \", len(imgfft.shape), \" dimensions.\")\n",
    "\n",
    "    # ifftshift\n",
    "    imgfft = np.fft.ifftshift(imgfft, axes=axes)\n",
    "\n",
    "    # ifft\n",
    "    complex_img = np.fft.ifftn(imgfft, axes = axes)\n",
    "\n",
    "    # shift img to center\n",
    "    complex_img = np.fft.fftshift(complex_img, axes=axes)\n",
    "    return complex_img\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kspace = cfl.readcfl(f'../../results/kspacesampling/u_kspaceM1_hr').squeeze().transpose(4, 0, 1, 2, 3)\n",
    "print('kspace shape:', kspace.shape)\n",
    "kspace = kspace[:, :, :, :, 0] #only use one sensitivity map\n",
    "\n",
    "u_recon   = np.angle(centered_kspace_to_complex_img(kspace))\n",
    "\n",
    "plt.imshow(np.abs(kspace[0, 100, :, :]))\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@widgets.interact(frame=(0, u_recon.shape[0]-1), x = (0, u_recon.shape[1]-1), axis=[0, 1, 2])\n",
    "def f(frame=5, x = 10,  axis = 0):\n",
    "    plt.figure(figsize=(3,3))\n",
    "    N = 2\n",
    "    idxs = get_indices(frame,axis, x)\n",
    "\n",
    "    plt.imshow(u_recon[idxs], vmin=0, vmax=np.pi)\n",
    "    plt.title('M1 phase image')\n",
    "    plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check on Signal to noise ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load coil sens file\n",
    "save_as = '../../results/kspacesampling'\n",
    "save_coil_sens = f'{save_as}/coil_sensitivity16_sphere'\n",
    "\n",
    "\n",
    "coil_images = cfl.readcfl(save_coil_sens).squeeze()\n",
    "if len(coil_images.shape) == 5:\n",
    "    coil_images = coil_images.transpose(4, 0, 1, 2, 3)\n",
    "n_coils = coil_images.shape[-1]\n",
    "\n",
    "print(coil_images.shape)\n",
    "\n",
    "for c in range(n_coils):\n",
    "    coil_image = coil_images[:, :, :, c]\n",
    "    print(coil_image.dtype, coil_image.max(), coil_image.min())\n",
    "    plt.subplot(1, n_coils, c+1)\n",
    "    plt.imshow(np.abs(coil_image[100, :, :]))\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_datamodel = '/mnt/c/Users/piacal/Code/SuperResolution4DFlowMRI/Temporal4DFlowNet/data/CARDIAC/M1_2mm_step2_static_dynamic.h5'\n",
    "\n",
    "# load data static and take frist frame\n",
    "with h5py.File(path_datamodel, 'r') as f:\n",
    "    M1_u = np.array(f['u'])[0]\n",
    "    M1_v = np.array(f['v'])[0]\n",
    "    M1_w = np.array(f['w'])[0]\n",
    "    venc = np.array(f['u_max'])[0]\n",
    "    mask = np.array(f['mask'])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add noise: \n",
    "targetSNRdb = 14\n",
    "M1_u_noise = fft_fcts.noise_and_downsampling(M1_u, mask, venc, targetSNRdb, add_noise=True, spatial_crop_ratio=1.0)\n",
    "\n",
    "snr_u = signaltonoise_fluid_region(M1_u, mask)\n",
    "print(snr_u, targetSNRdb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check k space sampling results and cs reconstruction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new new new \n",
    "cs_result_path = '../../results/kspacesampling/FromAlex/result_cs.h5'\n",
    "kspace_path =    '../../results/kspacesampling/FromAlex/alex_ksp'\n",
    "# cs_result_path =  '../../results/kspacesampling/res_cs_9coils.h5'#'../../results/kspacesampling/output_test16'#'../../results/kspacesampling/res_cs16_9coils_large.h5'\n",
    "# kspace_path =    '../../results/kspacesampling/u_kspace16'\n",
    "path_datamodel = '/mnt/c/Users/piacal/Code/SuperResolution4DFlowMRI/Temporal4DFlowNet/data/CARDIAC/M1_2mm_step2_static_dynamic.h5'\n",
    "\n",
    "# load the data\n",
    "with h5py.File(cs_result_path, 'r') as file:\n",
    "    print(file.keys())\n",
    "    cs_result = np.array(file['res'])\n",
    "\n",
    "# cs_result = reshape_from_cfl(cfl.readcfl(cs_result_path).squeeze())\n",
    "\n",
    "with h5py.File(path_datamodel, 'r') as f:\n",
    "    M1_u = np.array(f['u'])[::2]\n",
    "    M1_u_norm = vel_to_phase_norm(M1_u)\n",
    "    mask = np.array(f['mask'])[::2]\n",
    "\n",
    "kspace_orig = cfl.readcfl(kspace_path).squeeze().transpose(4, 0, 1, 2, 3)\n",
    "print(kspace_orig.shape, np.linalg.norm(kspace_orig[:, :, :, :, 0]-kspace_orig[:, :, :, :, 1]))\n",
    "kspace_orig0 = kspace_orig[:, :, :, :, 0]\n",
    "\n",
    "mask_large  = adjust_image_size(mask, kspace_orig0.shape)\n",
    "vel_p_large = adjust_image_size(M1_u_norm, kspace_orig0.shape)\n",
    "compl_img   = centered_kspace_to_complex_img(kspace_orig0)\n",
    "\n",
    "phase_cs   = np.angle(cs_result)*mask_large #np.angle(cs_result)*\n",
    "phase_orig = np.angle(compl_img)*mask_large\n",
    "\n",
    "\n",
    "vel_p_large =  (vel_p_large + np.pi)*mask_large\n",
    "phase_orig  =  (phase_orig  + np.pi)*mask_large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(phase_cs[0, 100, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phase_norm_to_vel(phase, min_vel, max_vel):\n",
    "    return (phase + np.pi) / np.pi * (max_vel - min_vel) + min_vel\n",
    "\n",
    "#note copied to kspace sampling\n",
    "def vel_to_phase_norm(vel):\n",
    "    return (vel-np.min(vel))/(np.max(vel) - np.min(vel)) * np.pi - np.pi\n",
    "\n",
    "\n",
    "#phase to velocity\n",
    "min_vel = M1_u.min()\n",
    "max_vel = M1_u.max()\n",
    "print(min_vel, max_vel)\n",
    "\n",
    "vel_cs = phase_norm_to_vel(phase_cs-np.pi, min_vel, max_vel) \n",
    "\n",
    "voxel_idx = np.index_exp[:, 91, 61, 50]\n",
    "# # voxel_idx = np.index_exp[:, 90, 60, 52]\n",
    "\n",
    "voxel_cs   = vel_cs[voxel_idx] \n",
    "vel_large  = adjust_image_size(M1_u, kspace_orig0.shape)\n",
    "voxel_vel = vel_large[voxel_idx]\n",
    "plt.plot(voxel_cs , label='cs')\n",
    "# plt.plot(voxel_orig , label='orig') #+ np.pi\n",
    "plt.plot(voxel_vel  , label='M1 vel') #- np.pi\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_idx = np.index_exp[:, 91, 61, 50]\n",
    "# voxel_idx = np.index_exp[:, 90, 60, 52]\n",
    "\n",
    "voxel_cs   = phase_cs[voxel_idx]\n",
    "voxel_orig = phase_orig[voxel_idx]\n",
    "voxel_vel = vel_p_large[voxel_idx]\n",
    "plt.plot(voxel_cs , label='cs')\n",
    "plt.plot(voxel_orig , label='orig') #+ np.pi\n",
    "plt.plot(voxel_vel  , label='M1 vel') #- np.pi\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_vel = np.min(vel_p_large)\n",
    "max_vel = np.max(vel_p_large)\n",
    "\n",
    "print(f\"Min vel: {min_vel}, max vel: {max_vel}\")\n",
    "print(f\"Min phase cs: {np.min(phase_cs)}, max phase cs: {np.max(phase_cs)}\")\n",
    "print(f\"Min phase orig: {np.min(phase_orig)}, max phase orig: {np.max(phase_orig)}\")\n",
    "\n",
    "@widgets.interact(frame=(0, phase_cs.shape[0]-1), x = (0, phase_cs.shape[1]-1), axis=[0, 1, 2])\n",
    "def f(frame=5, x = 10,  axis = 0):\n",
    "    plt.figure(figsize=(8,8))\n",
    "    N = 2\n",
    "    idxs = get_indices(frame,axis, x)\n",
    "\n",
    "    plt.subplot(1, 4, 1)\n",
    "    plt.imshow(vel_p_large[idxs], vmin=0, vmax=np.pi)\n",
    "    plt.title('M1 phase image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 4, 2)\n",
    "    plt.imshow(phase_cs[idxs], vmin=0, vmax=np.pi)\n",
    "    plt.title('CS phase image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 4, 3)\n",
    "    plt.imshow(phase_orig[idxs], vmin=0, vmax=np.pi)\n",
    "    plt.title('Phase image from kspace')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 4, 4)\n",
    "    plt.imshow(phase_orig[idxs]-vel_p_large[idxs])\n",
    "    plt.title('Diff M1 phase and cd phase')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "h5_files = ['../../results/kspacesampling/FromAlex/result_cs.h5','../../results/kspacesampling/res_cs16_9coils_large.h5', ]\n",
    "path_datamodel = '/mnt/c/Users/piacal/Code/SuperResolution4DFlowMRI/Temporal4DFlowNet/data/CARDIAC/M1_2mm_step2_static_dynamic.h5'\n",
    "colnames = ['res_vel']\n",
    "\n",
    "# load data\n",
    "with h5py.File(h5_files[0], 'r') as f:\n",
    "    alex_res = np.array(f['res'])\n",
    "\n",
    "with h5py.File(h5_files[1], 'r') as f:\n",
    "    new_res = np.array(f['resxmask'])\n",
    "\n",
    "with h5py.File(path_datamodel, 'r') as f:\n",
    "    M1_u = np.array(f['u'])[::2]\n",
    "    mask = np.array(f['mask'])[::2]\n",
    "\n",
    "\n",
    "mask_large = adjust_image_size(mask, alex_res.shape)\n",
    "\n",
    "alex_res_masked = mask_large * np.angle(alex_res)\n",
    "new_res_masked  = mask_large * np.angle(new_res)\n",
    "\n",
    "print(np.linalg.norm(alex_res_masked- new_res_masked))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@widgets.interact(frame=(0, alex_res_masked.shape[0]-1), x = (0, alex_res_masked.shape[1]-1), axis=[0, 1, 2])\n",
    "def f(frame=5, x = 10,  axis = 0):\n",
    "    plt.figure(figsize=(7,7))\n",
    "    N = 2\n",
    "    idxs = get_indices(frame,axis, x)\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(alex_res_masked[idxs])\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(new_res_masked[idxs])\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(new_res_masked[idxs] -alex_res_masked[idxs])\n",
    "    plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing a fibbonaci sphere where code is inspired from \n",
    " #   tps://stackoverflow.com/questions/9600801/evenly-distributing-n-points-on-a-sphere\n",
    "    # d adapted for an arbitrary sphere radius\n",
    "def fibonacci_sphere(samples=1000, r= 1):\n",
    "\n",
    "    points = []\n",
    "    tangent = []\n",
    "    phi = math.pi * (math.sqrt(5.) - 1.)  # golden angle in radians\n",
    "\n",
    "    for i in range(samples):\n",
    "        y = (1 - (i / float(samples - 1)) * 2) # y goes from 1 to -1\n",
    "        radius = math.sqrt(1 - y * y)*r  # radius at y\n",
    "\n",
    "        theta = phi * i  # golden angle increment\n",
    "\n",
    "        x = math.cos(theta) * radius\n",
    "        z = math.sin(theta) * radius\n",
    "\n",
    "        points.append((x, y*r, z))\n",
    "        tangent.append((-r*np.cos(theta)*np.sin(phi), 0, r*np.cos(theta)*np.cos(phi)))\n",
    "    \n",
    "    return points, tangent\n",
    "\n",
    "n = 20\n",
    "s_points, _  = fibonacci_sphere(n, 10)\n",
    "s_points2, _ = fibonacci_sphere(n, 2)\n",
    "s_points3, _ = fibonacci_sphere(n, 3)\n",
    "plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter([x[0] for x in s_points], [x[1] for x in s_points], [x[2] for x in s_points])\n",
    "ax.scatter([x[0] for x in s_points2], [x[1] for x in s_points2], [x[2] for x in s_points2])\n",
    "ax.scatter([x[0] for x in s_points3], [x[1] for x in s_points3], [x[2] for x in s_points3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#3D points\n",
    "radius= 2\n",
    "center = [0, 0, 0]\n",
    "normal = [1, 0, 1]\n",
    "area_vec = [-1, 2, -1]\n",
    "points = []\n",
    "angles = np.linspace(0, 2*np.pi, 20)\n",
    "\n",
    "for a in angles:\n",
    "    points.append((radius*np.cos(a)*area_vec[0]+ radius*np.cos(a)*(np.cross(normal, area_vec)[0]) + center[0], \n",
    "                   radius*np.cos(a)*area_vec[1]+ radius*np.sin(a)*(np.cross(normal, area_vec)[1]) + center[1],\n",
    "                   radius*np.cos(a)*area_vec[2]+ radius*np.sin(a)*(np.cross(normal, area_vec)[2]) + center[2]))\n",
    "points = np.array(points)\n",
    "print(points.shape)\n",
    "plt.figure()\n",
    "ax = plt.subplot(111, projection='3d')\n",
    "ax.scatter(points[:,0], points[:,1], points[:,2])\n",
    "ax.scatter(center[0], center[1], center[2], color = 'orange')\n",
    "\n",
    "#normal vector is the difference between center shere point and the center of the circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_points, tangents = fibonacci_sphere(30, 10)\n",
    "\n",
    "plt.figure()\n",
    "ax = plt.subplot(111, projection='3d')\n",
    "for i, point in enumerate(s_points):\n",
    "    # create circle for every sphere point\n",
    "    radius = 1\n",
    "    normal = np.array(point)/np.linalg.norm(np.array(point)) #since sphere is centered around origin\n",
    "\n",
    "    tangent1 = np.array(tangents[i]) \n",
    "    tangent1 /= np.linalg.norm(tangent1)\n",
    "    tangent2 = np.cross(normal, tangent1)\n",
    "    tangent2 /= np.linalg.norm(tangent2)\n",
    "    points_c = []\n",
    "    for a in angles:\n",
    "        points_c.append((radius*np.cos(a)*tangent1[0]+ radius*np.sin(a)*(tangent2[0]) + point[0], \n",
    "                         radius*np.cos(a)*tangent1[1]+ radius*np.sin(a)*(tangent2[1]) + point[1],\n",
    "                         radius*np.cos(a)*tangent1[2]+ radius*np.sin(a)*(tangent2[2]) + point[2]))\n",
    "    points_c = np.array(points_c)\n",
    "    ax.scatter(points_c[:,0], points_c[:,1], points_c[:,2], color ='blue')\n",
    "    ax.scatter(point[0], point[1], point[2], color = 'red')\n",
    "ax.scatter(0, 0, 0, color = 'orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming coil_images and data are your input arrays\n",
    "coil_images = np.random.rand(72, 70, 76, 3)\n",
    "data = np.random.rand(50, 72, 70, 76)\n",
    "\n",
    "# Reshape coil_images to (72, 70, 76, 1) to match the last dimension of data\n",
    "coil_images_reshaped = coil_images[np.newaxis, :, :, :, :]\n",
    "print( coil_images_reshaped.shape, data.shape)\n",
    "# Multiply coil_images with data\n",
    "result = coil_images[np.newaxis, :, :, :, :] * data[..., np.newaxis]\n",
    "\n",
    "print(result.shape)\n",
    "\n",
    "\n",
    "result2 = np.zeros((50, 72, 70, 76, 3))\n",
    "for c in range(3):\n",
    "    temp_res = coil_images[np.newaxis,  :, :, :, c] * data\n",
    "    temp_res2 = np.multiply(np.repeat(coil_images[np.newaxis,  :, :, :, c], data.shape[0], axis = 0), data)\n",
    "    print('diff tem res', np.linalg.norm(temp_res - temp_res2))\n",
    "    result2[:, :, :,: , c] = temp_res\n",
    "\n",
    "print('diff', np.linalg.norm(result -result2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check on fft and ifft\n",
    "data_dir = '/mnt/c/Users/piacal/Code/SuperResolution4DFlowMRI/Temporal4DFlowNet/data'\n",
    "path_datamodel = f'{data_dir}/CARDIAC/M1_2mm_step2_static_dynamic.h5'\n",
    "\n",
    "\n",
    "# load data\n",
    "with h5py.File(path_datamodel, mode = 'r') as h5:\n",
    "    vel_u = np.array(h5['u'])[::2, :, :, :]\n",
    "    venc_u = np.max(np.array(h5['u_max']))\n",
    "\n",
    "magn = np.ones_like(vel_u)\n",
    "\n",
    "# transform to kspace\n",
    "u_kspace = fft_fcts.velocity_img_to_centered_kspace(vel_u, magn, venc_u)\n",
    "\n",
    "plt.imshow(np.abs(u_kspace[0, 20, :, :]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load \n",
    "file = '../../results/interpolation/M2_2mm_step1_static_kspace_sampled_coilsens2.h5'\n",
    "with h5py.File(file, 'r') as f:\n",
    "    u_sensitivities = np.array(f['u_csens'])\n",
    "    u = np.array(f['u'])\n",
    "    coil_sens = np.array(f['sum_coil_images'])\n",
    "\n",
    "diff = u_sensitivities - u\n",
    "v_max = np.max(u)\n",
    "v_min = np.min(u)\n",
    "\n",
    "# plot\n",
    "\n",
    "@widgets.interact( x = (0, u.shape[1]-1))\n",
    "def f(x = 0):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    N  =4\n",
    "    plt.subplot(1, N, 1)\n",
    "    plt.imshow(u[ x, :, :], vmin=v_min,  vmax = v_max)\n",
    "    plt.title('u')\n",
    "    plt.axis('off')\n",
    "\n",
    "\n",
    "    plt.subplot(1, N, 2)\n",
    "    plt.imshow(u_sensitivities[x, :, :], vmin=v_min,  vmax = v_max)\n",
    "    plt.title('sen u')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, N, 3)\n",
    "    plt.imshow(diff[ x, :, :])\n",
    "    plt.title('diff')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, N, 4)\n",
    "    plt.imshow(np.abs(coil_sens[x, :, :]))\n",
    "    # plt.colorbar()\n",
    "    plt.title('coil sens')\n",
    "    plt.axis('off')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(u[np.where(u!=0)].flatten(), bins=100)\n",
    "plt.ylim(0, 23000)\n",
    "plt.xlim(-1, 1)\n",
    "plt.title('u')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(u_sensitivities[np.where(u!=0)].flatten(), bins=100)\n",
    "plt.title('u sensitivy filtered')\n",
    "plt.ylim(0, 23000)\n",
    "plt.xlim(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test different box averaging strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prepare_data.temporal_downsampling import temporal_box_averaging_and_downsampling\n",
    "\n",
    "data_dir = '../../data/CARDIAC/'\n",
    "hr_box_path = 'M4_2mm_step2_cloudmagnRot_boxavg_HRfct.h5'\n",
    "lr_box_path = 'M4_2mm_step2_cloudmagnRot_boxavg_LRfct_noise.h5'\n",
    "hrhr_box_path = 'M4_2mm_step1_static_dynamic.h5'\n",
    "\n",
    "lr_data = {}\n",
    "hr_data = {}\n",
    "with h5py.File(f'{data_dir}{hr_box_path}', 'r') as f:\n",
    "    for k in f.keys():\n",
    "        hr_data[k] = np.array(f[k]).squeeze()\n",
    "with h5py.File(f'{data_dir}{lr_box_path}', 'r') as f:\n",
    "    for k in f.keys():\n",
    "        lr_data[k] = np.array(f[k]).squeeze()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "vel_colnames = ['u', 'v', 'w']\n",
    "for i, vel in enumerate(vel_colnames):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    t_range = range(0, hr_data[vel].shape[0])\n",
    "    plt.plot(t_range, np.average(hr_data[vel], axis=(1, 2, 3),weights = lr_data['mask']), label=f'HR_{vel}', color = 'black')\n",
    "    plt.plot(t_range[::2], np.average(lr_data[vel][::2], axis=(1, 2, 3),weights = lr_data['mask'][::2]), label=f'LR_{vel} 1')\n",
    "    plt.plot(t_range[::2], np.average(lr_data[vel][1::2], axis=(1, 2, 3),weights = lr_data['mask'][::2]), label=f'LR_{vel} 2')\n",
    "\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "hrhr_data = {}\n",
    "# part 2: self sampling\n",
    "with h5py.File(f'{data_dir}{hrhr_box_path}', 'r') as f:\n",
    "    for k in f.keys():\n",
    "        hrhr_data[k] = np.array(f[k]).squeeze()\n",
    "\n",
    "# compute new averages\n",
    "new_box_avg = {}    \n",
    "u_box_avg_lr1, u_box_avg_lr2 = temporal_box_averaging_and_downsampling(hrhr_data['u'], 4)\n",
    "v_box_avg_lr1, v_box_avg_lr2 = temporal_box_averaging_and_downsampling(hrhr_data['v'], 4)\n",
    "w_box_avg_lr1, w_box_avg_lr2 = temporal_box_averaging_and_downsampling(hrhr_data['w'], 4)\n",
    "\n",
    "new_box_avg['u1'] = u_box_avg_lr1\n",
    "new_box_avg['u2'] = u_box_avg_lr2\n",
    "new_box_avg['v1'] = v_box_avg_lr1\n",
    "new_box_avg['v2'] = v_box_avg_lr2\n",
    "new_box_avg['w1'] = w_box_avg_lr1\n",
    "new_box_avg['w2'] = w_box_avg_lr2\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "for i, vel in enumerate(vel_colnames):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    t_range = range(0, hr_data[vel].shape[0])\n",
    "    plt.plot(t_range, np.average(hr_data[vel], axis=(1, 2, 3),weights = hr_data['mask']), label=f'HR_{vel}', color = 'black')\n",
    "\n",
    "\n",
    "    plt.plot(t_range[::2], np.average(new_box_avg[f'{vel}1'], axis=(1, 2, 3),weights = lr_data['mask'][::2]), label=f'LR_{vel} 1')\n",
    "    plt.plot(t_range[::2], np.average(new_box_avg[f'{vel}2'], axis=(1, 2, 3),weights = lr_data['mask'][::2]), label=f'LR_{vel} 2')\n",
    "\n",
    "\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"../../data/CARDIAC/M1_2mm_step1_static_dynamic.h5\"\n",
    "vel_colnames = ['u', 'v', 'w']\n",
    "\n",
    "data = {}\n",
    "with h5py.File(file, 'r') as f:\n",
    "    for key in f.keys():\n",
    "        data[key] = np.array(f[key]).squeeze()\n",
    "\n",
    "\n",
    "N_frames, x, y, z = data['u'].shape\n",
    "\n",
    "N_frames_25 = int(N_frames/4)\n",
    "\n",
    "sampling_1 = np.zeros((N_frames_25, x, y, z, 3))\n",
    "sampling_2 = np.zeros((N_frames_25, x, y, z, 3))\n",
    "sampling_3 = np.zeros((N_frames_25, x, y, z, 3))\n",
    "sampling_4 = np.zeros((N_frames_25, x, y, z, 3))\n",
    "sampling_5 = np.zeros((N_frames_25, x, y, z, 3))\n",
    "sampling_6 = np.zeros((N_frames_25, x, y, z, 3))\n",
    "\n",
    "# there are 6 or actually 7 different sanpling strategies\n",
    "for v, vel in enumerate(vel_colnames):\n",
    "    # append the first 4 frames to the end to include periodic boundaries\n",
    "    data_vel = np.concatenate((data[vel],data[vel][0:4]), axis=0)\n",
    "    for i in range(N_frames_25):\n",
    "        \n",
    "        sampling_1[i, :, :, :, v] = np.average(data_vel[4*i:4*i+4], axis=0)\n",
    "        sampling_2[i, :, :, :, v] = np.average(data_vel[4*i+1:4*i+5], axis=0)\n",
    "\n",
    "        sampling_3[i, :, :, :, v] = np.average(data_vel[4*i+2:4*i+6], axis=0)\n",
    "        sampling_4[i, :, :, :, v] = np.average(data_vel[4*i+3:4*i+7], axis=0)\n",
    "        sampling_5[i, :, :, :, v] = 0.5 * (data_vel[4*i] + data_vel[4*i+2])\n",
    "        sampling_6[i, :, :, :, v] = 0.5 * (data_vel[4*i+2] + data_vel[4*i+4])\n",
    "\n",
    "    # sampling_3=  np.roll(sampling_3, axis=0, shift=1)\n",
    "    # sampling_4=  np.roll(sampling_4, axis=0, shift=1)\n",
    "\n",
    "# caluculcate mean speed\n",
    "mean_speed1 = calculate_mean_speed(sampling_1[:,:, :, :, 0 ], sampling_1[:,:, :, :, 1 ], sampling_1[:,:, :, :, 2 ], binary_mask=data['mask'][::4])\n",
    "mean_speed2 = calculate_mean_speed(sampling_2[:,:, :, :, 0 ], sampling_2[:,:, :, :, 1 ], sampling_2[:,:, :, :, 2 ], binary_mask=data['mask'][::4])\n",
    "mean_speed3 = calculate_mean_speed(sampling_3[:,:, :, :, 0 ], sampling_3[:,:, :, :, 1 ], sampling_3[:,:, :, :, 2 ], binary_mask=data['mask'][::4])\n",
    "mean_speed4 = calculate_mean_speed(sampling_4[:,:, :, :, 0 ], sampling_4[:,:, :, :, 1 ], sampling_4[:,:, :, :, 2 ], binary_mask=data['mask'][::4])\n",
    "mean_speed5 = calculate_mean_speed(sampling_5[:,:, :, :, 0 ], sampling_5[:,:, :, :, 1 ], sampling_5[:,:, :, :, 2 ], binary_mask=data['mask'][::4])\n",
    "mean_speed6 = calculate_mean_speed(sampling_6[:,:, :, :, 0 ], sampling_6[:,:, :, :, 1 ], sampling_6[:,:, :, :, 2 ], binary_mask=data['mask'][::4])\n",
    "\n",
    "hr_mean_speed = calculate_mean_speed(data['u'], data['v'], data['w'], binary_mask=data['mask'])\n",
    "\n",
    "t_range = np.arange(0, N_frames, 4)\n",
    "t_range_hr = np.arange(0, N_frames)\n",
    "plt.plot(t_range_hr,hr_mean_speed,'-o',  label='HR', color = 'black')\n",
    "plt.plot(t_range_hr[::2], calculate_mean_speed(data['u'][::2], data['v'][::2], data['w'][::2], binary_mask=data['mask'][::2]),'o-', label='pointwise downsampling 1/2', color = 'grey')\n",
    "plt.plot(t_range_hr[::4], calculate_mean_speed(data['u'][::4], data['v'][::4], data['w'][::4], binary_mask=data['mask'][::4]),'o--', label='pointwise downsampling 1/4', color = 'lightgrey')\n",
    "\n",
    "plt.plot(t_range, mean_speed1, label='1/4 mean; offset 0')\n",
    "# plt.plot(t_range, mean_speed2, label='1/4 mean; offset 1')\n",
    "plt.plot(t_range, mean_speed3, label='1/4 mean; offset 2')\n",
    "# plt.plot(t_range, mean_speed4, label='1/4 mean; offset 3')\n",
    "# plt.plot(t_range, mean_speed5, label='5')\n",
    "# plt.plot(t_range[1:], mean_speed6[:-1], label='6')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dynamical_mask      = '../data/CARDIAC/M4_2mm_step2_static_dynamic.h5'#'../data/PIA/THORAX/P01/h5/P01.h5'#'../data/CARDIAC/M2_2mm_step2_static_dynamic.h5'\n",
    "noisy_downsampled   = '../data/CARDIAC/M4_2mm_step2_static_dynamic_noise.h5'\n",
    "# dynamical_mask = '../data/CARDIAC/M2_2mm_step2_invivoP04_magnitude.h5'\n",
    "# noisy_downsampled = '../data/CARDIAC/M2_2mm_step2_invivoP04_magnitude_noisy.h5'\n",
    "data_original = {}\n",
    "data_2 = {}\n",
    "vel_colnames = ['u', 'v','w']\n",
    "venc_colnames = [ 'u_max', 'v_max', 'w_max']\n",
    "mag_colnames = [ 'mag_u', 'mag_v', 'mag_w']\n",
    "vencs = {}\n",
    "\n",
    "with h5py.File(dynamical_mask, mode = 'r' ) as p1:\n",
    "    with h5py.File(noisy_downsampled, mode = 'r' ) as p2:\n",
    "            print(p1.keys())\n",
    "            mask =  np.asarray(p1['mask'])\n",
    "            temporal_mask = mask.copy()\n",
    "            data_original['mask'] = temporal_mask\n",
    "            data_2['mask'] = np.asarray(p2['mask']).squeeze()#create_temporal_mask(np.asarray(p2['mask']).squeeze(), p2['u'].shape[0])\n",
    "            # temporal_mask = create_temporal_mask(mask.squeeze(), p1['u'].shape[0])\n",
    "            for vel, venc, mag in zip(vel_colnames, venc_colnames, mag_colnames):\n",
    "                data_original[vel] = np.asarray(p1[vel])#/np.max(p1[venc])\n",
    "                data_2[vel] = np.asarray(p2[vel])#/np.max(p1[venc])\n",
    "\n",
    "                data_original[f'{vel}_fluid'] = np.multiply(data_original[vel], temporal_mask)\n",
    "                data_2[f'{vel}_fluid']  = np.multiply(data_2[vel] , temporal_mask)\n",
    "                data_original[mag] = np.asarray(p1[mag])\n",
    "                data_2[mag] = np.asarray(p2[mag])\n",
    "\n",
    "           \n",
    "\n",
    "print(data_original['mask'].shape, data_2['mask'].shape)\n",
    "# with h5py.File('../results/Temporal4DFlowNet_20230313-0951/Testset_result_model4_2mm_step2_0951_temporal.h5', mode = 'r' ) as test1:\n",
    "#      print(test1['u_combined'].shape)\n",
    "\n",
    "N_frames = data_original['u'].shape[0]\n",
    "print(\"Max val:\", np.max(data_original['u']), np.max(data_original['v']), np.max(data_original['w']))\n",
    "print(\"Min val:\", np.min(data_original['u']), np.min(data_original['v']), np.min(data_original['w']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magn = np.sqrt(data_2['mag_u']**2 + data_2['mag_v']**2 + data_2['mag_w']**2)\n",
    "speed = np.sqrt(data_2['u']**2 + data_2['v']**2 + data_2['w']**2)\n",
    "pc_mri = np.multiply(magn, speed)\n",
    "\n",
    "min_v = {}\n",
    "max_v = {}\n",
    "for vel in vel_colnames:\n",
    "    min_v[vel] = np.quantile(data_original[vel][np.where(temporal_mask !=0)].flatten(), 0.01)\n",
    "    max_v[vel] = np.quantile(data_original[vel][np.where(temporal_mask !=0)].flatten(), 0.99)\n",
    "\n",
    "idx_slice = np.index_exp[5, -30:-14, 30, 3:19]\n",
    "\n",
    "\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.imshow(data_2['u'][idx_slice], vmin = min_v['u'], vmax = max_v['u'])\n",
    "# plt.imshow(data_1['u_fluid'][idx_slice], vmin = min_v['u'], vmax = max_v['u'])\n",
    "plt.title(r'$V_x$')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.imshow(data_2['v'][idx_slice], vmin = min_v['v'], vmax = max_v['v'])\n",
    "# plt.imshow(data_1['v_fluid'][idx_slice], vmin = min_v['v'], vmax = max_v['v'])\n",
    "plt.title(r'$V_y$')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.imshow(data_2['w'][idx_slice], vmin = min_v['w'], vmax = max_v['w'])\n",
    "# plt.imshow(data_1['w_fluid'][idx_slice], vmin = min_v['w'], vmax = max_v['w'])\n",
    "plt.title(r'$V_z$')\n",
    "plt.axis('off')\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.imshow(magn[idx_slice], cmap='Greys_r')\n",
    "plt.title('Magnitude')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 5)\n",
    "plt.imshow(speed[idx_slice])\n",
    "plt.title('Speed')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 6)\n",
    "plt.imshow(pc_mri[idx_slice])\n",
    "plt.title('PC-MRA')\n",
    "plt.axis('off')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.imshow(data_original['u'][idx_slice], vmin = min_v['u'], vmax = max_v['u'])\n",
    "# plt.imshow(data_1['u_fluid'][idx_slice], vmin = min_v['u'], vmax = max_v['u'])\n",
    "plt.title(r'$V_x$')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.imshow(data_original['v'][idx_slice], vmin = min_v['v'], vmax = max_v['v'])\n",
    "# plt.imshow(data_1['v_fluid'][idx_slice], vmin = min_v['v'], vmax = max_v['v'])\n",
    "plt.title(r'$V_y$')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.imshow(data_original['w'][idx_slice], vmin = min_v['w'], vmax = max_v['w'])\n",
    "# plt.imshow(data_1['w_fluid'][idx_slice], vmin = min_v['w'], vmax = max_v['w'])\n",
    "plt.title(r'$V_z$')\n",
    "plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds, core = get_boundaries(data_original['mask'])\n",
    "speed_data_original = np.sqrt(data_original['u']**2 + data_original['v']**2 + data_original['w']**2)\n",
    "data_original['speed'] = np.sqrt(data_original['u']**2 + data_original['v']**2 + data_original['w']**2)\n",
    "print(f'Shapes: {bounds.shape}, {core.shape}, {speed.shape}')\n",
    "\n",
    "# print(f'sum core: {np.sum(core, axis=(1, 2, 3))}, sum bounds: {np.sum(bounds, axis = (1, 2, 3))}')\n",
    "\n",
    "# print(f'Mean speed core: {np.mean(speed, axis=(1, 2, 3), where=core.astype(bool))}')\n",
    "# print(f'Mean speed boundary: {np.mean(speed, axis=(1, 2, 3), where=bounds.astype(bool))}')\n",
    "\n",
    "print(f'Max Mean speed core: {np.max(np.mean(speed_data_original, axis=(1, 2, 3), where=core.astype(bool)))}')\n",
    "print(f'Max Mean speed boundary: {np.max(np.mean(speed_data_original, axis=(1, 2, 3), where=bounds.astype(bool)))}')\n",
    "\n",
    "mean_speed = calculate_mean_speed(data_original['u'], data_original['v'], data_original['w'], data_original['mask'])\n",
    "\n",
    "plt.plot(np.mean(speed_data_original, axis=(1, 2, 3), where=core.astype(bool)), label='core')\n",
    "plt.plot(np.mean(speed_data_original, axis=(1, 2, 3), where=bounds.astype(bool)), label='bounds')\n",
    "plt.plot(np.mean(speed_data_original, axis=(1, 2, 3), where=data_original['mask'].astype(bool)), label='mask')\n",
    "plt.plot(mean_speed/100, label='mean speed')\n",
    "plt.legend()\n",
    "\n",
    "mask_bool = data_original['mask'].astype(bool)\n",
    "mask = data_original['mask'].copy()\n",
    "\n",
    "# print(f'difference mean speed caluclations: {np.mean(speed_data_original, axis=(1, 2, 3), where=mask_bool)- mean_speed/100}')\n",
    "print(f'mean speed core max/ min {np.max(calculate_mean_speed(data_original[\"u\"], data_original[\"v\"], data_original[\"w\"], core))}, {np.min(calculate_mean_speed(data_original[\"u\"], data_original[\"v\"], data_original[\"w\"], core))}')\n",
    "print(f'mean speed bounds max/ min {np.max(calculate_mean_speed(data_original[\"u\"], data_original[\"v\"], data_original[\"w\"], bounds))}, {np.min(calculate_mean_speed(data_original[\"u\"], data_original[\"v\"], data_original[\"w\"], bounds))}')\n",
    "print(f'mean speed mask max/ min {np.max(calculate_mean_speed(data_original[\"u\"], data_original[\"v\"], data_original[\"w\"], mask))}, {np.min(calculate_mean_speed(data_original[\"u\"], data_original[\"v\"], data_original[\"w\"], mask))}')\n",
    "\n",
    "print(f'max speed core {np.multiply(speed_data_original, core).max()} min speed core {np.multiply(speed_data_original, core).min()}')\n",
    "print(f'max speed bounds {np.multiply(speed_data_original, bounds).max()} min speed bounds {np.multiply(speed_data_original, bounds).min()}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make data plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_slice = np.index_exp[5, 15, :, :]\n",
    "\n",
    "\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.imshow(data_2['u'][idx_slice], vmin = min_v['u'], vmax = max_v['u'])\n",
    "# plt.imshow(data_1['u_fluid'][idx_slice], vmin = min_v['u'], vmax = max_v['u'])\n",
    "plt.title(r'$V_x$')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.imshow(data_2['v'][idx_slice], vmin = min_v['v'], vmax = max_v['v'])\n",
    "# plt.imshow(data_1['v_fluid'][idx_slice], vmin = min_v['v'], vmax = max_v['v'])\n",
    "plt.title(r'$V_y$')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.imshow(data_2['w'][idx_slice], vmin = min_v['w'], vmax = max_v['w'])\n",
    "# plt.imshow(data_1['w_fluid'][idx_slice], vmin = min_v['w'], vmax = max_v['w'])\n",
    "plt.title(r'$V_z$')\n",
    "plt.axis('off')\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.imshow(magn[idx_slice], cmap='Greys_r')\n",
    "plt.title('Magnitude')\n",
    "plt.axis('off')\n",
    "\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dir = '../results/data'\n",
    "\n",
    "idx_slice = np.index_exp[5, :, 30, :]\n",
    "\n",
    "\n",
    "plt.imshow(data_2['u'][idx_slice], vmin = min_v['u'], vmax = max_v['u'])\n",
    "# plt.imshow(data_1['u_fluid'][idx_slice], vmin = min_v['u'], vmax = max_v['u'])\n",
    "plt.axis('off')\n",
    "plt.savefig(f'{eval_dir}/Slice_u.png', bbox_inches='tight')\n",
    "\n",
    "\n",
    "plt.imshow(data_2['v'][idx_slice], vmin = min_v['v'], vmax = max_v['v'])\n",
    "# plt.imshow(data_1['v_fluid'][idx_slice], vmin = min_v['v'], vmax = max_v['v'])\n",
    "plt.axis('off')\n",
    "plt.savefig(f'{eval_dir}/Slice_v.png',bbox_inches='tight')\n",
    "\n",
    "\n",
    "plt.imshow(data_2['w'][idx_slice], vmin = min_v['w'], vmax = max_v['w'])\n",
    "# plt.imshow(data_1['w_fluid'][idx_slice], vmin = min_v['w'], vmax = max_v['w'])\n",
    "plt.axis('off')\n",
    "plt.savefig(f'{eval_dir}/Slice_w.png', bbox_inches='tight')\n",
    "\n",
    "\n",
    "plt.imshow(magn[idx_slice], cmap='Greys_r')\n",
    "plt.axis('off')\n",
    "plt.savefig(f'{eval_dir}/Slice_mag.png', bbox_inches='tight')\n",
    "\n",
    "plt.imshow(speed[idx_slice])\n",
    "plt.axis('off')\n",
    "plt.savefig(f'{eval_dir}/Slice_speed.png', bbox_inches='tight')\n",
    "\n",
    "plt.imshow(pc_mri[idx_slice])\n",
    "plt.axis('off')\n",
    "plt.savefig(f'{eval_dir}/Slice_pcmri.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_i = 10\n",
    "u1_i_fluid = data_original['u'][frame_i][np.where(data_original['mask'][frame_i] ==1)]\n",
    "u2_i_fluid = data_2['u'][frame_i][np.where(data_original['mask'][frame_i] ==1)]\n",
    "# print(u1_i_fluid.shape)\n",
    "# print('gt SNR:',        signaltonoise(normalize_to_0_1(u1_i_fluid), axis=(0)))\n",
    "# print('noisy SNR :',    signaltonoise(normalize_to_0_1(u2_i_fluid), axis=(0)))\n",
    "# print('gt SNR db:',     signaltonoise_db(normalize_to_0_1(u1_i_fluid), axis=(0)))\n",
    "# print('noisy SNR db:',  signaltonoise_db(normalize_to_0_1(u2_i_fluid), axis=(0)))\n",
    "\n",
    "\n",
    "# print('PSNR db:', peak_signal_to_noise_ratio(data_1['u'][10], data_2['u'][10]), cv2_psnr(data_1['u'][10], data_2['u'][10]))\n",
    "\n",
    "# print('SNR :', signaltonoise(data_1['u'][10], axis=(0, 1, 2)))\n",
    "# snr_u_gt =    [signaltonoise_fluid_region(data_1['u'][frame], data_1['mask'][frame]) for frame in range(N_frames)]\n",
    "# snr_v_gt =    [signaltonoise_fluid_region(data_1['v'][frame], data_1['mask'][frame]) for frame in range(N_frames)]\n",
    "# snr_w_gt =    [signaltonoise_fluid_region(data_1['w'][frame], data_1['mask'][frame]) for frame in range(N_frames)]\n",
    "\n",
    "snr_u_noisy = [signaltonoise_fluid_region(data_2['u'][frame], data_original['mask'][frame]) for frame in range(N_frames)]\n",
    "snr_v_noisy = [signaltonoise_fluid_region(data_2['v'][frame], data_original['mask'][frame]) for frame in range(N_frames)]\n",
    "snr_w_noisy = [signaltonoise_fluid_region(data_2['w'][frame], data_original['mask'][frame]) for frame in range(N_frames)]\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "plt.plot(snr_u_noisy,'--', label= 'u noisy')\n",
    "plt.plot(snr_v_noisy,'--', label= 'v noisy')\n",
    "plt.plot(snr_w_noisy,'--', label= 'w noisy')\n",
    "# plt.plot(snr_u_gt,  label= 'u gt')\n",
    "# plt.plot(snr_v_gt,  label= 'v gt')\n",
    "# plt.plot(snr_w_gt,  label= 'w gt')\n",
    "plt.legend()\n",
    "plt.xlabel('frame')\n",
    "plt.ylabel('SNR mean/std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at sinc interpolation\n",
    "upsampled_sinc ='../data/CARDIAC/M4_2mm_step2_static_dynamic_noise_sinc.h5'\n",
    "noisy_downsampled = '../data/CARDIAC/M4_2mm_step2_static_dynamic_noise.h5'\n",
    "data_original = {}\n",
    "data_2 = {}\n",
    "vel_colnames = ['u', 'v','w']\n",
    "\n",
    "with h5py.File(noisy_downsampled, mode = 'r' ) as p1:\n",
    "    data_original['mask'] =  np.asarray(p1['mask'])\n",
    "    temporal_mask = np.asarray(data_original['mask']).squeeze().copy()\n",
    "    for vel in vel_colnames:\n",
    "        data_original[vel] = np.asarray(p1[vel])\n",
    "        data_original[f'{vel}_fluid'] = np.multiply(data_original[vel], temporal_mask)\n",
    "\n",
    "with h5py.File(upsampled_sinc, mode = 'r' ) as p2:\n",
    "    data_2['mask'] =  temporal_mask\n",
    "    for vel in vel_colnames:\n",
    "        data_2[vel] = np.asarray(p2[vel]).squeeze()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_periodic(func, t, interval, *args, **kwargs):\n",
    "    t_shifted = (t - (interval[0] - dt)) % (interval[1] - interval[0]) + (interval[0] - dt)\n",
    "    print(t_shifted)\n",
    "    return func(t_shifted, *args, **kwargs)\n",
    "\n",
    "# Example usage with the hat function\n",
    "def hat_function(t, width):\n",
    "    return np.where((t >= 0) & (t < width/2), t/(width/2), np.where((t >= width/2) & (t < width), 1 - (t-width/2)/(width/2), 0))\n",
    "\n",
    "def smoothed_box_fct(t, t0, w, sigma):\n",
    "            \"\"\"\n",
    "            Smoothed box function. With alpha = 1 this is not normalized to 1\n",
    "            \"\"\"\n",
    "            non_normalized = (1/(1+np.exp(-(t-(t0-w/2))/sigma)) - 1/(1+np.exp(-(t-(t0+w/2))/sigma)))\n",
    "            alpha = 1\n",
    "            # alpha = 1/integral_trapez(non_normalized, t)\n",
    "            return alpha * non_normalized\n",
    "\n",
    "# Example usage:\n",
    "time_points = np.linspace(0, 1, 10)  # Time points from 0 to 1\n",
    "interval = [0, 1]  # Specify the interval\n",
    "width = 0.2  # Adjust width of the hat function as needed\n",
    "\n",
    "smoothing = 0.004\n",
    "dt = time_points[1] - time_points[0]\n",
    "\n",
    "results = [make_periodic(smoothed_box_fct, time_points, interval, t_n, dt, smoothing) for t_n in time_points]\n",
    "\n",
    "\n",
    "print(-0.1%1)\n",
    "# Plot the result\n",
    "plt.plot(time_points, results, \"--\")\n",
    "plt.title('Periodic Hat Function')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Function Value')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load orginial data, HR smoothed and LR smoothed\n",
    "\n",
    "# plot mean speed over time and mean velocitty over time\n",
    "\n",
    "orginial_HR = '../data/CARDIAC/M4_2mm_step2_static_dynamic.h5'\n",
    "HR_smmoothed = '../data/CARDIAC/M4_2mm_step2_temporalsmoothing_toeger_periodic_HRfct.h5'\n",
    "LR_smmoothed = '../data/CARDIAC/M4_2mm_step2_temporalsmoothing_toeger_periodic_LRfct.h5'\n",
    "LR_with_noise = '../data/CARDIAC/M4_2mm_step2_temporalsmoothing_toeger_periodic_LRfct_noise.h5'\n",
    "\n",
    "\n",
    "\n",
    "data_original = {}\n",
    "data_HR = {}\n",
    "data_LR = {}\n",
    "data_LR_with_noise = {}\n",
    "vel_colnames = ['u', 'v','w']\n",
    "\n",
    "# load data\n",
    "with h5py.File(orginial_HR, mode = 'r' ) as p1:\n",
    "    with h5py.File(HR_smmoothed, mode = 'r' ) as p2:\n",
    "        with h5py.File(LR_smmoothed, mode = 'r' ) as p3:\n",
    "            with h5py.File(LR_with_noise, mode = 'r' ) as p4:\n",
    "                data_original['mask'] =  np.asarray(p1['mask'])\n",
    "                temporal_mask = np.asarray(data_original['mask']).squeeze().copy()\n",
    "                for vel in vel_colnames:\n",
    "                    data_original[vel] = np.asarray(p1[vel])\n",
    "                    data_original[f'{vel}_fluid'] = np.multiply(data_original[vel], temporal_mask)\n",
    "\n",
    "                    data_HR[vel] = np.asarray(p2[vel])\n",
    "                    data_HR[f'{vel}_fluid'] = np.multiply(data_HR[vel], temporal_mask)\n",
    "\n",
    "                    data_LR[vel] = np.asarray(p3[vel])\n",
    "                    data_LR[f'{vel}_fluid'] = np.multiply(data_LR[vel], temporal_mask)\n",
    "\n",
    "                    data_LR_with_noise[vel] = np.asarray(p4[vel])\n",
    "                    data_LR_with_noise[f'{vel}_fluid'] = np.multiply(data_LR_with_noise[vel], temporal_mask)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# calculate mean speed\n",
    "mean_speed_originalHR   = calculate_mean_speed(data_original['u'], data_original['v'], data_original['w'], data_original['mask'])\n",
    "mean_speed_HR_smoothed  = calculate_mean_speed(data_HR['u'], data_HR['v'], data_HR['w'], data_original['mask'])\n",
    "mean_speed_LR_smoothed  = calculate_mean_speed(data_LR['u'], data_LR['v'], data_LR['w'], data_original['mask'])\n",
    "mean_speed_LR_with_noise  = calculate_mean_speed(data_LR_with_noise['u'], data_LR_with_noise['v'], data_LR_with_noise['w'], data_original['mask'])\n",
    "\n",
    "plt.plot(mean_speed_originalHR, 'o--', label='original')\n",
    "plt.plot(mean_speed_HR_smoothed,'o--', label='HR smoothed')\n",
    "plt.plot(mean_speed_LR_smoothed,'o--', label='LR smoothed')\n",
    "plt.plot(mean_speed_LR_with_noise,'o--', label='LR with noise')\n",
    "plt.legend()\n",
    "plt.xlabel('frame')\n",
    "plt.ylabel('mean speed cm/s')\n",
    "plt.title('Mean speed over time')\n",
    "plt.show()\n",
    "\n",
    "# compare Vx velocity\n",
    "\n",
    "plt.plot(np.mean(data_original['u'], axis=(1, 2, 3)), 'o--', label='original')\n",
    "plt.plot(np.mean(data_HR['u'], axis=(1, 2, 3)), 'o--', label='HR smoothed')\n",
    "plt.plot(np.mean(data_LR['u'], axis=(1, 2, 3)), 'o--', label='LR smoothed')\n",
    "plt.plot(np.mean(data_LR_with_noise['u'], axis=(1, 2, 3)), 'o--', label='LR with noise')\n",
    "plt.legend()\n",
    "plt.xlabel('frame')\n",
    "plt.ylabel('mean speed m/s')\n",
    "plt.title('Mean Vx velocity over time')\n",
    "plt.show()\n",
    "\n",
    "# compare Vy velocity\n",
    "\n",
    "plt.plot(np.mean(data_original['v'], axis=(1, 2, 3)), 'o--', label='original')\n",
    "plt.plot(np.mean(data_HR['v'], axis=(1, 2, 3)), 'o--', label='HR smoothed')\n",
    "plt.plot(np.mean(data_LR['v'], axis=(1, 2, 3)), 'o--', label='LR smoothed')\n",
    "plt.plot(np.mean(data_LR_with_noise['v'], axis=(1, 2, 3)), 'o--', label='LR with noise')\n",
    "plt.legend()\n",
    "plt.xlabel('frame')\n",
    "plt.ylabel('mean speed m/s')\n",
    "plt.title('Mean Vy velocity over time')\n",
    "plt.show()\n",
    "\n",
    "# compare Vz velocity\n",
    "\n",
    "plt.plot(np.mean(data_original['w'], axis=(1, 2, 3)), 'o--', label='original')\n",
    "plt.plot(np.mean(data_HR['w'], axis=(1, 2, 3)), 'o--', label='HR smoothed')\n",
    "plt.plot(np.mean(data_LR['w'], axis=(1, 2, 3)), 'o--', label='LR smoothed')\n",
    "plt.plot(np.mean(data_LR_with_noise['w'], axis=(1, 2, 3)), 'o--', label='LR with noise')\n",
    "plt.legend()\n",
    "plt.xlabel('frame')\n",
    "plt.ylabel('mean speed m/s')\n",
    "plt.title('Mean Vz velocity over time')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blochs equations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import odeint, solve_ivp, complex_ode\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Define Bloch equations\n",
    "def bloch_equations(t, y, B0, gamma, T1, T2, M0):\n",
    "    \"\"\" Bloch equation where V = 0 \n",
    "    \"\"\"\n",
    "    assert T2 < T1, \"T2 relaxation must be faster than T1 relaxation\"\n",
    "\n",
    "    Mx, My, Mz = y\n",
    "    omega = gamma * B0\n",
    "    Bgz = 1\n",
    "    B1 = 1\n",
    "    B1x = B1* np.cos(omega * t)\n",
    "    B1y = -B1* np.sin(omega * t)\n",
    "\n",
    "\n",
    "    dMxdt = omega * (My*Bgz - Mz*B1y) - Mx/ T2\n",
    "    dMydt = omega * (Mz*B1x - Mx*Bgz) -(My / T2)\n",
    "    dMzdt = omega * (Mx*B1y - My*B1x) -(Mz - M0) / T1 \n",
    "\n",
    "    return [dMxdt, dMydt, dMzdt]\n",
    "\n",
    "# Bloch-Gleichungen\n",
    "def bloch_equations_2(t, y, gamma, B0, T1, T2):\n",
    "    mx, my, mz = y\n",
    "    omega = gamma * B0\n",
    "\n",
    "    dmxdt = omega * my - mx / T2\n",
    "    dmydt = -omega * mx - my / T2\n",
    "    dmzdt = (1 - mz) / T1 - omega * mx\n",
    "\n",
    "    return [dmxdt, dmydt, dmzdt]\n",
    "\n",
    "\n",
    "# Parameters\n",
    "B0 = 1.5  # Magnetic field strength in Tesla\n",
    "gamma = 267538030.3797/B0#42.58e6  # Gyromagnetic ratio for protons in rad/(s*T)\n",
    "T1 = 0.005  # Longitudinal relaxation time in seconds\n",
    "T2 = 0.002 # Transverse relaxation time in seconds\n",
    "\n",
    "# Initial magnetization\n",
    "y0 = [1.0, 0.0, 0.0]  # Ensure M0 is a flat, one-dimensional array\n",
    "M0 = 7.0\n",
    "# Time points\n",
    "t = np.linspace(0, 0.1, 1001)\n",
    "\n",
    "# Solve Bloch equations\n",
    "solution = complex_ode(bloch_equations, y0, t, args=(B0, gamma, T1, T2, M0), )\n",
    "\n",
    "t_span = (0, 2.0)  # Start- und Endzeit\n",
    "t_eval = np.linspace(*t_span, 1000)  # Zeitpunkte für die Auswertung\n",
    "\n",
    "# Lösung der Bloch-Gleichungen\n",
    "# solution = solve_ivp(\n",
    "#     bloch_equations,\n",
    "#     t_span,\n",
    "#     y0,\n",
    "#     args=(gamma, B0, T1, T2, M0),\n",
    "#     t_eval=t_eval,\n",
    "#     method=\"RK45\",\n",
    "# )\n",
    "\n",
    "\n",
    "# Extract components of magnetization\n",
    "Mx, My, Mz = solution.T\n",
    "\n",
    "print(Mx, My, Mz)\n",
    "# Print or use the results as needed\n",
    "\n",
    "# Plot trajectory in 3D\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(Mx, My, Mz)\n",
    "ax.set_xlabel('Mx')\n",
    "ax.set_ylabel('My')\n",
    "ax.set_zlabel('Mz')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(solution)\n",
    "Mx, My, Mz = solution.y\n",
    "\n",
    "print(solution.y.shape)\n",
    "print(Mx, My, Mz)\n",
    "# Print or use the results as needed\n",
    "\n",
    "# Plot trajectory in 3D\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(Mx, My, Mz)\n",
    "ax.set_xlabel('Mx')\n",
    "ax.set_ylabel('My')\n",
    "ax.set_zlabel('Mz')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "B0 = 1.5  # Magnetic field strength in Tesla\n",
    "gamma = 42.58e6  # gyromagnetisches Verhältnis für Wasserstoff in Hz/T\n",
    "T1 = 0.05  # Longitudinal relaxation time in seconds\n",
    "T2 = 0.02 # Transverse relaxation time in seconds\n",
    "M0 = 2.0\n",
    "t = np.linspace(0, 0.3, 10001)\n",
    "print(t)\n",
    "A = 1\n",
    "freq = B0 * gamma\t\n",
    "Mx = M0* np.exp(-t/T2)*np.sin(freq * t)\n",
    "My = M0*np.exp(-t/T2)* np.cos(freq * t)\n",
    "Mxy = np.sqrt(Mx**2 + My**2)\n",
    "Mz = M0*(1- np.exp(-t/T1))\n",
    "# Bext = np.linspace(0, 10, t.shape[0])\n",
    "\n",
    "# Plot trajectory in 3D\n",
    "\n",
    "@widgets.interact(T1=(0.001, 0.03, 0.01), T2=(0.001, 0.03,0.01))\n",
    "def f(T1 = 0.05, T2=0.02):\n",
    "\n",
    "    # define Mx, My, Mz\n",
    "    Mx = M0* np.exp(-t/T2)*np.sin(freq * t)\n",
    "    My = M0*np.exp(-t/T2)* np.cos(freq * t)\n",
    "    Mz = M0*(1- np.exp(-t/T1))\n",
    "\n",
    "    # plot\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(Mx, My, Mz, cmap = 'viridis', c = t)\n",
    "    ax.plot(Mx, My, Mz)\n",
    "    ax.set_xlabel('Mx')\n",
    "    ax.set_ylabel('My')\n",
    "    ax.set_zlabel('Mz')\n",
    "\n",
    "    # ax2 = fig.add_subplot(111)\n",
    "    # ax2.plot(t, Mx, label='Mx')\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "fig = plt.figure(figsize=(5, 2))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot(Mx, My, Mz)\n",
    "ax.scatter(Mx, My, Mz, cmap = 'viridis', c = t)\n",
    "ax.set_xlabel('Mx')\n",
    "ax.set_ylabel('My')\n",
    "ax.set_zlabel('Mz')\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(t, Mx, label='Mx')\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(t, Mxy,   label='Mxy')\n",
    "plt.plot(t, My,\"--\", label='My')\n",
    "plt.legend()\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(t, Mz, label='Mz')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Bloch-Gleichungen\n",
    "def bloch_equations(t, y, gamma, B0, T1, T2):\n",
    "    mx, my, mz = y\n",
    "    omega = gamma * B0\n",
    "\n",
    "    dmxdt = omega * my - mx / T2\n",
    "    dmydt = -omega * mx - my / T2\n",
    "    dmzdt = (1 - mz) / T1 - omega * mx\n",
    "\n",
    "    return [dmxdt, dmydt, dmzdt]\n",
    "\n",
    "# Simulationsparameter\n",
    "gamma = 42.58e6  # gyromagnetisches Verhältnis für Wasserstoff in Hz/T\n",
    "B0 = 3.0  # Stärke des externen Magnetfelds in Tesla\n",
    "T1 = 1.0  # Längsrelaxationszeit in Sekunden\n",
    "T2 = 0.1  # Querrelaxationszeit in Sekunden\n",
    "\n",
    "# Anfangsbedingungen\n",
    "mx0, my0, mz0 = 1.0, 0.0, 0.0  # Anfangsmagnetisierung in x-Richtung\n",
    "\n",
    "# Zeitpunkte für die Lösung der Bloch-Gleichungen\n",
    "t_span = (0, 2.0)  # Start- und Endzeit\n",
    "t_eval = np.linspace(*t_span, 1000)  # Zeitpunkte für die Auswertung\n",
    "\n",
    "# Lösung der Bloch-Gleichungen\n",
    "solution = solve_ivp(\n",
    "    bloch_equations,\n",
    "    t_span,\n",
    "    [mx0, my0, mz0],\n",
    "    args=(gamma, B0, T1, T2),\n",
    "    t_eval=t_eval,\n",
    "    method=\"RK45\",\n",
    ")\n",
    "\n",
    "# Plotten des Bloch-Vektor-Diagramms\n",
    "plt.plot(solution.y[0], solution.y[1])\n",
    "plt.title(\"Bloch Vektor Diagramm\")\n",
    "plt.xlabel(\"$m_x$\")\n",
    "plt.ylabel(\"$m_y$\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mx = M0* np.exp(-t/T2)*np.sin(1 * t)\n",
    "My = M0* np.exp(-t/T2)*np.cos(1 * t)\n",
    "\n",
    "plt.plot(t, Mx, label='Mx')\n",
    "plt.plot(t, My, label='My')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temporal_mask.shape)\n",
    "min_v = {}\n",
    "max_v = {}\n",
    "for vel in vel_colnames:\n",
    "    min_v[vel] = np.quantile(data_original[vel][np.where(temporal_mask !=0)].flatten(), 0.01)\n",
    "    max_v[vel] = np.quantile(data_original[vel][np.where(temporal_mask !=0)].flatten(), 0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compare temporal smoothing function by toeger to high ressolution data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_file = '../data/CARDIAC/M3_2mm_step2_invivoP03_magn_temporalsmoothing_toeger_periodic_HRfct.h5'\n",
    "temporal_smoothing_file = \"../data/CARDIAC/M3_2mm_step2_invivoP03_magn_temporalsmoothing_toeger_periodic_LRfct_noise.h5\"\n",
    "\n",
    "# load data\n",
    "with h5py.File(hr_file, mode = 'r' ) as p1:\n",
    "    u_hr = np.asarray(p1['u'])\n",
    "    mask = np.asarray(p1['mask'])\n",
    "    # magn = np.asarray(p1['mag_u'])\n",
    "with h5py.File(temporal_smoothing_file, mode = 'r' ) as p2:\n",
    "    u_temporal_smoothing = np.asarray(p2['u'])\n",
    "    magn = np.asarray(p2['mag_u'])\n",
    "    \n",
    "\n",
    "#find lower and higher values to display velocity fields\n",
    "min_v = np.quantile(u_hr[np.where(mask !=0)].flatten(), 0.01)\n",
    "max_v = np.quantile(u_hr[np.where(mask !=0)].flatten(), 0.99)\n",
    "\n",
    "# interactive display of velocity fields\n",
    "@widgets.interact(frame=(0, u_hr.shape[0]-1), x = (0, u_hr.shape[1]-1))\n",
    "def f(frame=5, x = 0):\n",
    "    plt.subplot(1, 4, 1)\n",
    "    idx_slice = np.index_exp[frame, x, :, :]\n",
    "    plt.imshow(u_hr[idx_slice], vmin=min_v, vmax=max_v)\n",
    "    plt.title('hr velocity u')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 4, 2)\n",
    "    plt.imshow(u_temporal_smoothing[idx_slice], vmin=min_v, vmax=max_v)\n",
    "    plt.title('temp smoothing u')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 4, 3)\n",
    "    plt.imshow(u_hr[idx_slice] - u_temporal_smoothing[idx_slice],)\n",
    "    plt.title('diff')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 4, 4)\n",
    "    plt.imshow(magn[idx_slice], cmap='Greys_r')\n",
    "    plt.axis('off')\n",
    "    plt.title('magnitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([1, 2,3 ,4, 5])\n",
    "print(A[-3:])\n",
    "periodic_weighting = np.zeros(6)\n",
    "weightning = np.arange(0, 11)\n",
    "\n",
    "len_trange = len(periodic_weighting)\n",
    "len_l = 2\n",
    "len_r = 3\n",
    "\n",
    "print(weightning)\n",
    "print(periodic_weighting)\n",
    "print(len(periodic_weighting))\n",
    "\n",
    "periodic_weighting = weightning[len_l:len_l+len_trange] # middle\n",
    "print(len(periodic_weighting))\n",
    "periodic_weighting[:len_r] += weightning[-len_r:] \n",
    "periodic_weighting[-len_l:] += weightning[:len_l]\n",
    "\n",
    "print(periodic_weighting)\n",
    "print(len(periodic_weighting))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In vivo data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at in vivo data\n",
    "in_vivo = '../data/PIA/BARCELONA/h5/sample_patient_newmask.h5'\n",
    "# in_vivo_upsampled = '../data/PIA/BARCELONA/h5/sample_patient.h5'\n",
    "in_vivo_upsampled = '../results/in_vivo/BARCELONA/20230405-1417_temporal.h5' # _newshape\n",
    "# in_vivo = '../data/PIA/THORAX/P01/h5/P01.h5'\n",
    "# in_vivo_upsampled = '../results/in_vivo/THORAX/P01_20230405-1417_temporal.h5' #image.png\n",
    "data_original = {}\n",
    "data_predicted = {}\n",
    "vencs = {}\n",
    "vel_colnames = ['u', 'v','w']\n",
    "mag_colnames = ['mag_u', 'mag_v', 'mag_w']\n",
    "venc_colnames = [  'u_max', 'v_max', 'w_max']\n",
    "\n",
    "\n",
    "\n",
    "#load in-vivo data\n",
    "with h5py.File(in_vivo, mode = 'r' ) as p1:\n",
    "    data_original['mask'] =  np.asarray(p1['mask']).squeeze()\n",
    "    print(p1.keys())\n",
    "    for vel, venc in zip(vel_colnames, venc_colnames):\n",
    "        vencs[venc] = np.asarray(p1[venc])\n",
    "        data_original[vel] = np.asarray(p1[vel], dtype = float).squeeze()/np.max(p1[venc]) #TODO change this\n",
    "        data_original[f'{vel}_fluid'] = np.multiply(data_original[vel], data_original['mask'])\n",
    "    for mag in mag_colnames:\n",
    "         data_original[mag] =  np.asarray(p1[mag]).squeeze()\n",
    "\n",
    "#load prediction\n",
    "with h5py.File(in_vivo_upsampled, mode = 'r' ) as h_pred:\n",
    "    for vel, venc in zip(vel_colnames, venc_colnames):\n",
    "        data_predicted[vel] = np.asarray(h_pred[f'{vel}_combined']) /np.max(vencs[venc]) \n",
    "        # add information considering only the fluid regions  \n",
    "        data_predicted[f'{vel}_fluid'] =np.multiply(data_predicted[vel], data_original['mask'])\n",
    "        \n",
    "# print(data_predicted['u'].shape, data_1['u'].shape)\n",
    "N_frames = data_original['u'].shape[0]\n",
    "print(\"Max val:\", np.max(data_original['u']), np.max(data_original['v']), np.max(data_original['w']))\n",
    "print(\"Min val:\", np.min(data_original['u']), np.min(data_original['v']), np.min(data_original['w']))\n",
    "\n",
    "# print(np.linalg.norm(data_1['mask']- data_predicted['mask']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('pred SNR:', signaltonoise(normalize_to_0_1(data_predicted['u'][10]), axis=(0, 1, 2)))\n",
    "print('noisy SNR :', signaltonoise(normalize_to_0_1(data_original['u'][10]), axis=(0, 1, 2)))\n",
    "print('pred SNR db:', signaltonoise_db(normalize_to_0_1(data_predicted['u'][10]), axis=(0, 1, 2)))\n",
    "print('noisy SNR db:', signaltonoise_db(normalize_to_0_1(data_original['u'][10]), axis=(0, 1, 2)))\n",
    "snr_u_input = [signaltonoise_db(normalize_to_0_1(data_original['u'][frame]), axis=(0, 1, 2)) for frame in range(N_frames)]\n",
    "snr_v_input = [signaltonoise_db(normalize_to_0_1(data_original['v'][frame]), axis=(0, 1, 2)) for frame in range(N_frames)]\n",
    "snr_w_input = [signaltonoise_db(normalize_to_0_1(data_original['w'][frame]), axis=(0, 1, 2)) for frame in range(N_frames)]\n",
    "snr_u_sr =    [signaltonoise_db(normalize_to_0_1(data_predicted['u'][frame]), axis=(0, 1, 2)) for frame in range(N_frames)]\n",
    "snr_v_sr =    [signaltonoise_db(normalize_to_0_1(data_predicted['v'][frame]), axis=(0, 1, 2)) for frame in range(N_frames)]\n",
    "snr_w_sr =    [signaltonoise_db(normalize_to_0_1(data_predicted['w'][frame]), axis=(0, 1, 2)) for frame in range(N_frames)]\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(snr_u_input,'--', label= 'u in-vivo')\n",
    "plt.plot(snr_v_input,'--', label= 'v in-vivo')\n",
    "plt.plot(snr_w_input,'--', label= 'w in-vivo')\n",
    "plt.plot(snr_u_sr, label= 'u predicted')\n",
    "plt.plot(snr_v_sr, label= 'v predicted')\n",
    "plt.plot(snr_w_sr, label= 'w predicted')\n",
    "plt.legend()\n",
    "plt.xlabel('frame')\n",
    "plt.ylabel('SNR mean/std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_linear_interpolation_np_test(lr, hr_shape):\n",
    "    T, x, y, z = hr_shape\n",
    "    interpolate = np.zeros((hr_shape))\n",
    "    interpolate[::2, :, :, :] = lr\n",
    "    for t in range(0, T-2, 2):\n",
    "        interpolate[1+t, :, :, :] = (interpolate[t, :, :, :] + interpolate[1+t+1, :, :, :]) /2\n",
    "\n",
    "    return interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find lower and higher values to display velocity fields\n",
    "min_v = {}\n",
    "max_v = {}\n",
    "for vel in vel_colnames:\n",
    "    min_v[vel] = np.quantile(data_original[vel][np.where(data_original['mask'] !=0)].flatten(), 0.01)\n",
    "    max_v[vel] = np.quantile(data_original[vel][np.where(data_original['mask'] !=0)].flatten(), 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# interpolate data (take every second slice and interpolate them)\n",
    "interpolate_linear = {}\n",
    "interpolate_cubic = {}\n",
    "for vel in vel_colnames:\n",
    "    interpolate_linear[vel] = temporal_linear_interpolation_np_test(data_original[vel][::2], data_original[vel].shape)\n",
    "    interpolate_linear[f'{vel}_fluid'] = np.multiply(interpolate_linear[vel], data_original['mask'])\n",
    "\n",
    "    # interpolate_cubic[vel] = temporal_cubic_interpolation(data_1[vel][::2], data_1[vel].shape)\n",
    "    # interpolate_cubic[f'{vel}_fluid'] = np.multiply(interpolate_cubic[vel], data_1['mask'])\n",
    "\n",
    "error_pointwise, error_absolut = calculate_pointwise_error(data_predicted[\"u\"], data_predicted[\"v\"], data_predicted[\"w\"], data_original[\"u\"], data_original[\"v\"] , data_original[\"w\"], data_original[\"mask\"])\n",
    "\n",
    "# visualize given data\n",
    "magn = np.sqrt(data_original['mag_u']**2 + data_original['mag_v']**2 + data_original['mag_w']**2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize in - vivo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at in vivo data\n",
    "in_vivo_oldmask = '../data/PIA/BARCELONA/BARCELONA2/h5/case_004.h5'\n",
    "data_original = {}\n",
    "\n",
    "#load in-vivo data\n",
    "with h5py.File(in_vivo_oldmask, mode = 'r' ) as p1:\n",
    "    for vel in vel_colnames:\n",
    "        data_original[vel] = np.array(p1[vel]).squeeze() \n",
    "    for mag in mag_colnames:\n",
    "        data_original[mag] = np.array(p1[mag]).squeeze() \n",
    "    print(p1.keys())\n",
    "    data_original['mask'] =  np.asarray(p1['mask']).squeeze()  \n",
    "    for key in p1.keys():\n",
    "        print(key, 'shape', p1[key].shape)\n",
    "    \n",
    "    # print(np.array(p1['v_max']))\n",
    "\n",
    "# print('Norm loaded masks:', np.linalg.norm(data_original['mask']- data_original['mask_old']))\n",
    "\n",
    "\n",
    "@widgets.interact(frame=(0, data_original['u'].shape[0]-1), x = (0, data_original['u'].shape[1]-1))\n",
    "def f(frame=5, x = 0):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    N  =3\n",
    "    plt.subplot(1, N, 1)\n",
    "    plt.imshow(data_original['u'][frame, x, :, :])#, vmin=min_v['u'],  vmax = max_v['u'])\n",
    "    plt.title('Data, u')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # plt.subplot(1, N, 2)\n",
    "    # plt.imshow(data_original['u_fluid'][frame, x, :, :], vmin=min_v['u'],  vmax = max_v['u'])\n",
    "    # plt.title('new mask')\n",
    "    # plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, N, 2)\n",
    "    plt.imshow(data_original['mag_u'][frame, x, :, :])\n",
    "    plt.title('mag')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, N, 3)\n",
    "    plt.imshow(data_original['mask'][frame, x, :, :])#-data_original['mask'][frame, x, :, :])\n",
    "    plt.title('mask')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # plt.subplot(1, 4, 3)\n",
    "    # plt.imshow(magn[frame, x, :, :], cmap ='Greys')#,vmin=min_v['u'], vmax = max_v['u'])\n",
    "    # plt.title('magnitude')\n",
    "    # plt.axis('off')\n",
    "\n",
    "    # plt.subplot(1, 4, 4)\n",
    "    # plt.imshow(data_1['mask'][frame, x, :, :], cmap ='Greys')#,vmin=min_v['u'], vmax = max_v['u'])\n",
    "    # plt.title('mask')\n",
    "    # plt.axis('off')\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Norm loaded masks:', np.linalg.norm(data_original['mask']- data_original['mask_old']))\n",
    "\n",
    "# make mask from predicted region\n",
    "mask_predicted = np.zeros_like(data_predicted['v'])\n",
    "mask_predicted[np.where(data_predicted['v'] !=0)]\n",
    "\n",
    "print('Norm predicted mask and loaded mask', np.linalg.norm(data_original['mask']- mask_predicted))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show comparison of prediction and original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@widgets.interact(frame=(0, data_original['u'].shape[0]-1), x = (0, data_original['u'].shape[1]-1))\n",
    "def f(frame=5, x = 0):\n",
    "    idx_slice = np.index_exp[frame, x, :, :]\n",
    "\n",
    "    \n",
    "\n",
    "    plt.subplot(3, 4, 1)\n",
    "    plt.imshow(data_original['u'][idx_slice], vmin = min_v['u'], vmax = max_v['u'])\n",
    "    # plt.imshow(data_1['u_fluid'][idx_slice], vmin = min_v['u'], vmax = max_v['u'])\n",
    "    plt.title('u')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(3, 4, 2)\n",
    "    plt.imshow(data_original['v'][idx_slice], vmin = min_v['v'], vmax = max_v['v'])\n",
    "    # plt.imshow(data_1['v_fluid'][idx_slice], vmin = min_v['v'], vmax = max_v['v'])\n",
    "    plt.title('v')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(3, 4, 3)\n",
    "    plt.imshow(data_original['w'][idx_slice], vmin = min_v['w'], vmax = max_v['w'])\n",
    "    # plt.imshow(data_1['w_fluid'][idx_slice], vmin = min_v['w'], vmax = max_v['w'])\n",
    "    plt.title('w')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(3, 4, 4)\n",
    "    plt.imshow(data_original['mask'][idx_slice], cmap ='Greys')\n",
    "    plt.title('mask')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(3, 4, 5)\n",
    "    plt.imshow(data_predicted['u'][idx_slice], vmin = min_v['u'], vmax = max_v['u'])\n",
    "    plt.title('u predicted')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(3, 4, 6)\n",
    "    plt.imshow(data_predicted['v'][idx_slice], vmin = min_v['v'], vmax = max_v['v'])\n",
    "    plt.title('v predicted')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(3, 4, 7)\n",
    "    plt.imshow(data_predicted['w'][idx_slice], vmin = min_v['w'], vmax = max_v['w'])\n",
    "    plt.title('w predicted')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(3, 4, 8)\n",
    "    plt.imshow(magn[idx_slice], cmap ='Greys')\n",
    "    plt.title('magnitude')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(3, 4, 9)\n",
    "    plt.imshow(np.abs(data_original['u_fluid'][idx_slice]- data_predicted['u_fluid'][idx_slice]), vmin = min_v['u'], vmax = max_v['u'], cmap = 'coolwarm')\n",
    "    plt.title('abs diff u, fluid region')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(3, 4, 10)\n",
    "    plt.imshow(np.abs(data_original['v_fluid'][idx_slice] - data_predicted['v_fluid'][idx_slice]), vmin = min_v['v'], vmax = max_v['v'], cmap = 'coolwarm')\n",
    "    plt.title('abs diff v, fluid region')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(3, 4, 11)\n",
    "    plt.imshow(np.abs(data_original['w_fluid'][idx_slice] -data_predicted['w_fluid'][idx_slice]), vmin = min_v['w'], vmax = max_v['w'], cmap = 'coolwarm')\n",
    "    plt.title('abs diff w, fluid region')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(3, 4, 12)\n",
    "    plt.imshow(error_pointwise[idx_slice], cmap = 'coolwarm')\n",
    "    plt.title('relative error')\n",
    "    plt.axis('off')\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show relative error of prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate relative error\n",
    "rel_error = calculate_relative_error_normalized(data_predicted[\"u\"], data_predicted[\"v\"], data_predicted[\"w\"], data_original[\"u\"], data_original[\"v\"] , data_original[\"w\"], data_original[\"mask\"])\n",
    "rel_error_lin_interpolation =   calculate_relative_error_normalized(interpolate_linear[\"u\"], interpolate_linear[\"v\"], interpolate_linear[\"w\"], data_original[\"u\"], data_original[\"v\"] , data_original[\"w\"], data_original[\"mask\"])\n",
    "\n",
    "\n",
    "data_original['mean_speed'] = calculate_mean_speed(data_original[\"u_fluid\"], data_original[\"v_fluid\"] , data_original[\"w_fluid\"], data_original[\"mask\"])\n",
    "data_predicted['mean_speed'] = calculate_mean_speed(data_predicted[\"u_fluid\"], data_predicted[\"v_fluid\"] , data_predicted[\"w_fluid\"], data_original[\"mask\"])\n",
    "interpolate_linear['mean_speed'] = calculate_mean_speed(interpolate_linear[\"u_fluid\"], interpolate_linear[\"v_fluid\"] ,interpolate_linear[\"w_fluid\"], data_original[\"mask\"])\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.subplot(2, 1, 1)\n",
    "frames = len(rel_error)\n",
    "plt.title(\"Relative error\")\n",
    "plt.plot(rel_error, label = 'Thorax P01 prediction')\n",
    "plt.plot(rel_error_lin_interpolation[:-1], label = 'linear interpolation',color = 'yellowgreen')\n",
    "# plt.plot(rel_error_cubic_interpolation, label = 'cubic interpolation', color = 'forestgreen')\n",
    "plt.plot(50*np.ones(len(rel_error)), 'k:')\n",
    "plt.xlabel(\"Frame\")\n",
    "plt.ylabel(\"Relative error (%)\")\n",
    "plt.ylim((0, 100))\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title('Mean speed')\n",
    "plt.plot(calculate_mean_speed(data_predicted[\"u_fluid\"], data_predicted[\"v_fluid\"], data_predicted[\"w_fluid\"],data_original[\"mask\"]), label = 'predicted', color= 'steelblue')\n",
    "plt.plot(calculate_mean_speed(data_original[\"u_fluid\"], data_original[\"v_fluid\"], data_original[\"w_fluid\"],data_original[\"mask\"]),'--', label = 'data', color= 'black')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### correlation plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get boundary points\n",
    "bounds, core_mask = get_boundaries(data_original['mask'])\n",
    "plt.figure(figsize=(15, 5))\n",
    "plot_correlation(data_original, data_predicted, bounds=bounds, frame_idx=13)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@widgets.interact(frame=(0, data_original['u'].shape[0]-1), x = (0, data_original['u'].shape[1]-1))\n",
    "def f(frame=5, x = 0):\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(data_original['u'][frame, x, :, :], vmin=min_v['u'],  vmax = max_v['u'])\n",
    "    plt.title('Noisy')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(data_2['u'][frame//2, x, :, :],vmin=min_v['u'], vmax = max_v['u'])\n",
    "    plt.title('Sinc upsampled')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_original['speed']   = np.sqrt(data_original[\"u\"]**2 + data_original[\"v\"]**2 + data_original[\"w\"]**2)\n",
    "data_2['speed']   = np.sqrt(data_2[\"u\"]**2 + data_2[\"v\"]**2 + data_2[\"w\"]**2)\n",
    "# print(np.min(data_1['speed'][40, 25, :,:]), np.max(data_1['speed'][40, 25, :,:]))\n",
    "slice_idx = np.index_exp[6,34, :, :]\n",
    "\n",
    "min_v = {}\n",
    "max_v = {}\n",
    "\n",
    "# min_v['speed'] = np.quantile(data_2['speed'][slice_idx].flatten(), 0.1)#np.min(data_2['speed'][slice_idx] )#\n",
    "max_v['speed'] = np.quantile(data_2['speed'][slice_idx].flatten(), 0.7)#np.max(data_2['speed'][slice_idx] )#\n",
    "\n",
    "im = data_2['speed'][slice_idx]\n",
    "\n",
    "plt.figure()\n",
    "ax = plt.gca()\n",
    "im1 = ax.imshow(im, vmin= 0, vmax=max_v['speed'])\n",
    "# plt.imshow(im, vmin= 0, vmax=max_v['speed'])\n",
    "plt.axis('off')\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "   \n",
    "plt.colorbar(im1, cax=cax)\n",
    "# plt.colorbar()\n",
    "#plt.colorbar(im,fraction=0.046, pad=0.04) \n",
    "plt.savefig('../results/data/Model1_speed_viridis_LR.png',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.imshow(data_original['speed'][slice_idx], vmin= 0, vmax=max_v['speed'])\n",
    "plt.axis('off')\n",
    "plt.colorbar()\n",
    "plt.savefig('../results/data/Model3_speed_viridis_LR.png',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Difference:\", np.linalg.norm(data_2['mask']- data_1['mask']))\n",
    "overlap_mask= np.zeros_like(data_original['u'])\n",
    "overlap_mask[np.where(data_original['u'] != 0)] = 1\n",
    "overlap_mask[np.where(data_original['v'] != 0)] = 1\n",
    "overlap_mask[np.where(data_original['w'] != 0)] = 1\n",
    "\n",
    "\n",
    "print(np.linalg.norm(overlap_mask - data_original['mask']))\n",
    "print(np.count_nonzero(data_2['mask']- data_original['mask']))\n",
    "print('Shape ', data_2['mask'].shape, 'total number of pixels: ', np.prod(data_2['mask'].shape), ' i.e.', np.prod(data_2['mask'].shape)/np.count_nonzero(data_2['mask']- data_original['mask']), ' %' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_mask = data_original['mask']\n",
    "def get_bounds(binary_mask):\n",
    "\n",
    "    core_mask = binary_erosion(binary_mask)\n",
    "    boundary_mask = mask - core_mask\n",
    "    # kernel_x = np.array([[-1,1]])\n",
    "    # kernel_y = kernel_x.transpose()\n",
    "\n",
    "    # boundary = np.abs(convolve2d(binary_mask, kernel_x, mode ='same')) + np.abs(convolve2d(binary_mask, kernel_y, mode = 'same' ))\n",
    "    # boundary[np.where(boundary !=0)] = 1\n",
    "    return boundary_mask, core_mask\n",
    "#get boundary points\n",
    "bounds, inner_mask = get_bounds(temporal_mask)# = #np.zeros_like(temporal_mask)\n",
    "# for t in range(temporal_mask.shape[0]):\n",
    "#     for i in range(temporal_mask.shape[0]):\n",
    "#         bounds[t, i, :, :] = get_bounds(temporal_mask[t, i, :, :])\n",
    "\n",
    "bounds_mask = bounds.copy()\n",
    "# inner_mask = np.asarray(temporal_mask, dtype= float) - np.asarray(bounds_mask, dtype = float)\n",
    "# inner_mask[np.where(inner_mask != 0 )] = 1\n",
    "print(np.unique(inner_mask, return_counts=True),np.unique(temporal_mask, return_counts=True),np.unique(bounds_mask, return_counts=True), bounds_mask.shape, temporal_mask.shape)\n",
    "print(np.count_nonzero(inner_mask))\n",
    "print(np.unravel_index(np.argmax(inner_mask), shape = inner_mask.shape))\n",
    "print(np.linalg.norm((inner_mask + bounds) - temporal_mask))\n",
    "@widgets.interact(frame=(0, data_original['u'].shape[0]-1), x = (0, data_original['u'].shape[1]-1))\n",
    "def f(frame=5, x = 0):\n",
    "    diff = temporal_mask - bounds\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(data_original['mask'][frame, x, :, :] )#vmin=min_v, vmax= max_v)\n",
    "    plt.title('Dynamical Mask')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(bounds[frame, x, :, :])#vmin=min_v, vmax= max_v)\n",
    "    plt.title('Boundary')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(diff[frame, x, :, :])#vmin=min_v, vmax= max_v)\n",
    "    plt.title('inner mask')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_v = {}\n",
    "max_v = {}\n",
    "for vel in vel_colnames:\n",
    "    min_v[vel] = np.quantile(data_original[vel][np.where(temporal_mask !=0)].flatten(), 0.01)\n",
    "    max_v[vel] = np.quantile(data_original[vel][np.where(temporal_mask !=0)].flatten(), 0.99)\n",
    "@widgets.interact(frame=(0, data_original['u'].shape[0]-1), x = (0, data_original['u'].shape[1]-1))\n",
    "def f(frame=5, x = 0):\n",
    "    vel = 'u'\n",
    "    diff = data_original[vel] - data_2[f'{vel}_fluid']\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(data_original[vel][frame, x, :, :], vmin=min_v[vel], vmax= max_v[vel])\n",
    "    plt.title('HR')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(data_2[f'{vel}_fluid'][frame, x, :, :], vmin=min_v[vel], vmax= max_v[vel])\n",
    "    plt.title('LR noisy mask region')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(diff[frame, x, :, :])#vmin=min_v, vmax= max_v)\n",
    "    plt.title('Difference within mask')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(p2[\"u\"][np.where(temporal_mask !=0)].flatten(), bins = 1000, color='red', label = 'not radial')   \n",
    "plt.hist(p1[\"u\"][np.where(temporal_mask !=0)].flatten(), bins = 1000, color='black', label = 'radial')  \n",
    "plt.xlim(np.quantile(p1[\"u\"][np.where(temporal_mask !=0)].flatten(), 0.01), np.quantile(p1[\"u\"][np.where(temporal_mask !=0)].flatten(), 0.99))\n",
    "plt.xlabel('value')\n",
    "plt.title(\"Distribution of velocity values in fluid region without outliers - radial\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(p2[\"u\"][np.where(temporal_mask !=0)].flatten() - p1[\"u\"][np.where(temporal_mask !=0)].flatten(), bins = 1000, color='blue', label = 'difference')  \n",
    "plt.xlim(np.quantile(p1[\"u\"][np.where(temporal_mask !=0)].flatten(), 0.01), np.quantile(p1[\"u\"][np.where(temporal_mask !=0)].flatten(), 0.99))\n",
    "plt.xlabel('value')\n",
    "plt.title(\"Difference\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/CARDIAC'\n",
    "    \n",
    "# ---- Patch index files ----\n",
    "training_file = '{}/Temporal14MODEL12_2mm_step2.csv'.format(data_dir)\n",
    "\n",
    "# Hyperparameters optimisation variables\n",
    "epochs =  1\n",
    "batch_size =10\n",
    "\n",
    "patch_size = 14\n",
    "res_increase = 2\n",
    "\n",
    "\n",
    "# Load data file and indexes\n",
    "trainset = load_indexes(training_file)\n",
    "\n",
    "# ----------------- TensorFlow stuff -------------------\n",
    "# TRAIN dataset iterator\n",
    "z = PatchHandler4D(data_dir, patch_size, res_increase, batch_size)\n",
    "trainset = z.initialize_dataset(trainset, shuffle=False, n_parallel=2)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}\")\n",
    "    start_time = time.time()\n",
    "    for i, data_pairs in enumerate(trainset):\n",
    "        start_loop = time.time()\n",
    "        \n",
    "        a = data_pairs\n",
    "        #check if datapairs align\n",
    "        lr_u, hr_u_mask, mask = check_compatibility(a)\n",
    "\n",
    "        message = f\"Iteration {i+1}   - batch {time.time()-start_loop:.4f} sec {time.time()-start_time:.1f} secs\"\n",
    "        print(f\"\\r{message}\", end='')\n",
    "        print(' ________________________')\n",
    "        #break\n",
    "        \n",
    "print(\"\\nDone\")#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_timeframes(gt,lr,  pred,mask, rel_error, dt,  timepoints, axis, idx, save_as = \"Frame_comparison.png\")\n",
    "# check interpolation result\n",
    "\n",
    "\n",
    "p1 = data_original['u_fluid']#lr['u']\n",
    "p2 = interpolate_linear['u_fluid'] #temporal_linear_interpolation(lr[\"u\"],gt[\"u\"].shape)\n",
    "p3 = interpolate_linear['v']#temporal_cubic_interpolation(lr[\"u\"],gt[\"u\"].shape)\n",
    "p4 = p2.copy()\n",
    "#p3[::2, :, :, :] -= p1\n",
    "p4 -= p1\n",
    "print(\"shapes_\", p1.shape, p2.shape, p3.shape)\n",
    "\n",
    "# min_v = -1#np.min(hr_u_downsampled)\n",
    "# max_v = 1#np.max(hr_u_downsampled)\n",
    "# #p3[np.where(p3 !=0)] = 1\n",
    "\n",
    "\n",
    "@widgets.interact(frame=(0, p2.shape[0]-1), x = (0, p2.shape[1]-1))\n",
    "def f(frame=5, x = 0):\n",
    "    plt.subplot(1, 3, 1)\n",
    "    #plt.imshow(p1[frame//2, x, :, :])#, vmin=min_v, vmax= max_v)\n",
    "    # if frame%2 == 0:\n",
    "    #     plt.imshow(p1[frame//2, x, :, :])#,  vmin = min_v[vel[0]], vmax = max_v[vel[0]], cmap='viridis')\n",
    "    # else:\n",
    "    #     plt.imshow(np.zeros_like(p1[frame//2, x, :, :]))#, vmin = min_v[vel[0]], vmax = max_v[vel[0]], cmap='viridis')\n",
    "    plt.imshow(p1[frame, x, :, :])\n",
    "    plt.title(\"data\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(p2[frame, x, :, :])#, vmin=min_v, vmax= max_v)\n",
    "    plt.title(\"Linear interpolation\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    # plt.subplot(1, 4, 3)\n",
    "    # plt.imshow(p3[frame, x, :, :])#, vmin=min_v, vmax= max_v)\n",
    "    # plt.title(\"Cubic interpolation\")\n",
    "    # plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(p4[frame, x, :, :])#, vmin=min_v, vmax= max_v, cmap='gray')\n",
    "    plt.title(\"Difference\")\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = mask\n",
    "p2 = hr_u_mask\n",
    "p3 = mask-hr_u_mask\n",
    "print(\"shapes_\", p1.shape, p2.shape, p3.shape)\n",
    "\n",
    "min_v = -1#np.min(hr_u_downsampled)\n",
    "max_v = 1#np.max(hr_u_downsampled)\n",
    "#p3[np.where(p3 !=0)] = 1\n",
    "overlap_masks = np.count_nonzero(p3)\n",
    "print(\"Check compatibility of masks! Nonzero difference:\", overlap_masks, '/', np.prod(list(hr_u_mask.shape)), 'i.e. ', 100*overlap_masks/np.prod(np.array(hr_u_mask.shape)) ,\"%\") \n",
    "\n",
    "\n",
    "@widgets.interact(frame=(0, p1.shape[0]-1), x = (0, p1.shape[1]-1))\n",
    "def f(frame=5, x = 0):\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(p1[frame, x, :, :], vmin=min_v, vmax= max_v)\n",
    "    plt.title('Gt mask')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(p2[frame, x, :, :], vmin=min_v, vmax= max_v)\n",
    "    plt.title(\"Non zero values for hr data\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(p3[frame, x, :, :], vmin=min_v, vmax= max_v, cmap='gray')\n",
    "    plt.title(\"Difference\")\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dir = '../results/in_vivo/VINCENT/' \n",
    "vincent_path = '../data/PIA/VINCENT/17.6ms/VINCENT_17_6.h5'\n",
    "v_data = {}\n",
    "with h5py.File(vincent_path, mode = 'r' ) as p1:\n",
    "    print(p1.keys())\n",
    "    v_data['maybemag'] = np.asarray(p1['maybemag'])\n",
    "    v_data['maybemag2'] = np.asarray(p1['maybemag2'])\n",
    "    print(v_data['maybemag'].shape, v_data['maybemag2'].shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# plt.imshow(v_data['maybemag'][idx_slice])\n",
    "\n",
    "@widgets.interact(frame=(0, v_data['maybemag2'].shape[0]-1), x = (0, v_data['maybemag2'].shape[1]-1))\n",
    "def f(frame=5, x = 0):\n",
    "    plt.subplot(1, 2, 1)\n",
    "    idx_slice = np.index_exp[frame, x, :, :]\n",
    "    plt.imshow(v_data['maybemag2'][idx_slice], cmap= 'Greys_r')\n",
    "    plt.title('Vincents mag')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(v_data['maybemag'][idx_slice])\n",
    "    plt.title('Vincents velocity')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_temporal_comparison_gif_single(spatial_idx, data,  min_v, max_v, title, colormap = 'viridis'):\n",
    "\n",
    "    print(title, 'nframes:', data.shape[0])\n",
    "    fig = plt.figure(frameon=False)\n",
    "    im1 = plt.imshow(data[0, spatial_idx[0], spatial_idx[1], spatial_idx[2]],interpolation='none', vmin=min_v, vmax=max_v, cmap = colormap)\n",
    "    # plt.title(title)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    #fig.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=None, hspace=None)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    #initialization function: plot the background of each frame\n",
    "    def init():\n",
    "        im1.set_data(np.random.random((5,5)))\n",
    "        return [im1]\n",
    "\n",
    "    # animation function.  This is called sequentially\n",
    "    def animate(i):\n",
    "        im1.set_array(data[i, spatial_idx[0], spatial_idx[1], spatial_idx[2]])\n",
    "        return [im1]\n",
    "\n",
    "    anim = animation.FuncAnimation(fig,animate, init_func=init,\n",
    "                                frames = data.shape[0],\n",
    "                                interval = 100, repeat = False) # in ms)\n",
    "    anim.save(f'{eval_dir}/Animate_invivo_{title}_18_faster2.gif', fps=30)\n",
    "\n",
    "idx_slice = np.index_exp[ 30, 40:, :]\n",
    "create_temporal_comparison_gif_single(idx_slice, v_data['maybemag2'], 0, np.quantile(v_data['maybemag2'][10], 0.99), title=f'Vincent_mag', colormap='Greys_r' )\n",
    "create_temporal_comparison_gif_single(idx_slice, v_data['maybemag'], np.quantile(v_data['maybemag'][10,  idx_slice[0], idx_slice[1], idx_slice[2]], 0.01), np.quantile(v_data['maybemag'][10,  idx_slice[0], idx_slice[1], idx_slice[2]], 0.99), title=f'Vincent_v', colormap='Greys_r' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_1 = '../data/CARDIAC/M1_2mm_step2_invivoP01_magnitude_adapted_noise.h5'\n",
    "file_2 = '../data/CARDIAC/M1_2mm_step2_invivoP01_magnitude_adapted_noisy.h5'\n",
    "\n",
    "mag_colnames = ['mag_u', 'mag_v', 'mag_w']\n",
    "\n",
    "data_1 = {}\n",
    "data_2 = {}\n",
    "with h5py.File(file_1, mode = 'r' ) as p1:\n",
    "    with h5py.File(file_2, mode = 'r') as p2:\n",
    "        for mag in mag_colnames:\n",
    "            data_1[mag] = np.asarray(p1[mag])\n",
    "            data_2[mag] = np.asarray(p2[mag])\n",
    "            print('diff:', np.linalg.norm(data_1[mag] - data_2[mag]))\n",
    "\n",
    "print(data_1['mag_u'].shape, data_2['mag_u'].shape)\n",
    "\n",
    "\n",
    "@widgets.interact(frame=(0, data_1['mag_u'].shape[0]-1), x = (0, data_1['mag_u'].shape[1]-1))\n",
    "def f(frame=5, x = 0):\n",
    "    plt.subplot(1, 3, 1)\n",
    "    idx_slice = np.index_exp[frame, x, :, :]\n",
    "    plt.imshow(data_1['mag_u'][idx_slice], cmap= 'Greys_r')\n",
    "    plt.title('New uncompressed mag')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(data_2['mag_u'][idx_slice], cmap= 'Greys_r')\n",
    "    plt.title('Old compressed mag')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(data_1['mag_u'][idx_slice] - data_2['mag_u'][idx_slice], cmap= 'Greys_r')\n",
    "    plt.title('Difference')\n",
    "    plt.axis('off')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_vivo_path = '../data/PIA/THORAX/P01/h5/P01.h5'\n",
    "data_original = {}\n",
    "vel_colnames = ['u', 'v','w']\n",
    "venc_colnames = [ 'u_max', 'v_max', 'w_max']\n",
    "mag_colnames = [ 'mag_u', 'mag_v', 'mag_w']\n",
    "vencs = {}\n",
    "\n",
    "with h5py.File(in_vivo_path, mode = 'r' ) as p1:\n",
    "            mask =  np.asarray(p1['mask'])\n",
    "            temporal_mask = mask.copy()\n",
    "            data_original['mask'] = temporal_mask\n",
    "            for vel, venc, mag in zip(vel_colnames, venc_colnames, mag_colnames):\n",
    "                data_original[vel] = np.asarray(p1[vel])\n",
    "                data_original[f'{vel}_fluid'] = np.multiply(data_original[vel], temporal_mask)\n",
    "                data_original[mag] = np.asarray(p1[mag])\n",
    "\n",
    "\n",
    "N_frames = data_original['u'].shape[0]\n",
    "print(\"Max val:\", np.max(data_original['u']), np.max(data_original['v']), np.max(data_original['w']))\n",
    "print(\"Min val:\", np.min(data_original['u']), np.min(data_original['v']), np.min(data_original['w']))\n",
    "\n",
    "bounds, core_mask = get_boundaries(temporal_mask)\n",
    "magn = np.sqrt(data_original['mag_u']**2 + data_original['mag_v']**2 + data_original['mag_w']**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@widgets.interact(frame=(0, data_original['u'].shape[0]-1), x = (0, data_original['u'].shape[1]-1))\n",
    "def f(frame=5, x = 0):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    N  =3\n",
    "    plt.subplot(1, N, 1)\n",
    "    plt.imshow(data_original['u'][frame, x, :, :], vmin=min_v['u'],  vmax = max_v['u'])\n",
    "    plt.title('Data, u')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # plt.subplot(1, N, 2)\n",
    "    # plt.imshow(data_original['u_fluid'][frame, x, :, :], vmin=min_v['u'],  vmax = max_v['u'])\n",
    "    # plt.title('new mask')\n",
    "    # plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, N, 2)\n",
    "    plt.imshow(data_original['mag_u'][frame, x, :, :])\n",
    "    plt.title('mag')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, N, 3)\n",
    "    plt.imshow(data_original['mask'][frame, x, :, :])#-data_original['mask'][frame, x, :, :])\n",
    "    plt.title('mask')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "idx_plane = np.index_exp[30, :, :]\n",
    "cube_plane = np.zeros_like(data_original['u'][0])\n",
    "\n",
    "cube_plane[idx_plane] = 1 # change this for every slice\n",
    "x_plane, y_plane, z_plane = np.where(cube_plane == 1)\n",
    "x_bounds, y_bounds, z_bounds = np.where(bounds[0, :, :, :] ==1)\n",
    "intersec_plane = data_original['mask'][0, :, :, :].copy()\n",
    "# intersec_plane += np.array(cube_plane, dtype = np.uint16)\n",
    "# intersec_plane[np.where(cube_plane == 1)] = 0\n",
    "intersec_plane[idx_plane] +=1\n",
    "x_intersec, y_intersec, z_intersec = np.where(intersec_plane == 2)\n",
    "\n",
    "fig = plt.figure()\n",
    "# ax.view_init(15, angle)\n",
    "#plt.zlabel('z')\n",
    "ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
    "\n",
    "ax.scatter3D(x_plane, y_plane, z_plane, color = 'grey',alpha = 0.01 )\n",
    "ax.scatter3D(x_bounds, y_bounds, z_bounds, s= 3, alpha = 0.1)\n",
    "ax.scatter3D(x_intersec, y_intersec, z_intersec, s= 3, alpha = 0.1, color = 'black')\n",
    "\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "ax.set_zlabel('z')\n",
    "plt.savefig('../results/data/THORAX')\n",
    "plt.show()\n",
    "plt.imshow(data_original['u'][10][idx_plane])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "585aea28fa87079cc8bffb5238657fadf631df6c8c1a15c467e95f4da754a260"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
